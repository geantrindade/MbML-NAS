{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "other-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plastic-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/Code/nns_performance_prediction/meta_datasets/', help='location of the dataset')    \n",
    "parser.add_argument('--model_path', type=str, default='/home/gean/Code/nns_performance_prediction/saved_models/fast/test1/', help='path to save the trained models')\n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/Code/nns_performance_prediction/results/fast/test1/', help='location of the results directory')    \n",
    "parser.add_argument('--target', type=str, default='final_validation_accuracy', help='target of the training/test')\n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 12, 36, 108], help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "parser.add_argument('--seed', type=int, default=[0, 42], nargs='+', help='seeds used for all the random procedures') \n",
    "parser.add_argument('--train_size', type=int, default=[43, 86, 129, 172, 344, 860], help='[Int, Int...] representing the total number of train samples')\n",
    "\n",
    "parser.add_argument('--estimators', type=str, default=['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor',\n",
    "                                                       'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', \n",
    "                                                       'DummyRegressor'], nargs='+', help='list of sklearn estimators to be used for training') \n",
    "\n",
    "parser.add_argument('--features_drop', type=str, default=['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', \n",
    "                                                          'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy'], \n",
    "                    nargs='+', help='list of features to drop from nasbench101')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finished-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharing-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_numpy_dataset(data_subset):\n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench101_' + str(data_subset) + 'epochs_tabular.csv'))\n",
    "    df_whole.drop(args.features_drop, axis=1, inplace=True)\n",
    "    df_whole = pd.get_dummies(df_whole)\n",
    "    \n",
    "    df_y = df_whole[args.target]\n",
    "    df_X = df_whole.drop([args.target], axis = 1)\n",
    "    X = df_X.to_numpy()\n",
    "    y = df_y.to_numpy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cellular-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_whole(estimator, X_train, y_train, X_test, y_test):\n",
    "    tic = time.time()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    toc = time.time()\n",
    "    print(\"Training DONE\")\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"Testing DONE\\n\\n\")\n",
    "    \n",
    "    return y_pred, (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "durable-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator(file_name: str):\n",
    "    estimator = load(str(args.model_path + file_name + '.joblib'))\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charitable-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(performance_dict, n, file_name): \n",
    "    df_results = pd.DataFrame.from_dict(performance_dict)\n",
    "    df_results.to_csv(str(args.results_path + \"N\" + str(n) + \"_\" + file_name + '.csv'),\n",
    "                      index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fourth-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions_and_fittime():\n",
    "    for n in args.train_size:\n",
    "        predictions = {}\n",
    "        fit_times = {'LinearRegression': [], 'SGDRegressor': [], 'Lasso': [], 'BayesianRidge': [], 'KNeighborsRegressor': [], 'DecisionTreeRegressor': [], 'SVR': [], \n",
    "                     'MLPRegressor': [], 'RandomForestRegressor': [], 'AdaBoostRegressor': [], 'GradientBoostingRegressor': [], 'DummyRegressor': []}\n",
    "\n",
    "        for seed in args.seed:\n",
    "            set_default_seed(seed)\n",
    "\n",
    "            for subset in args.data_subset:\n",
    "                X, y = get_preprocessed_numpy_dataset(subset)\n",
    "                print(\"\\n\\n######### Seed\", seed, \", Subset\", subset, \", N\", n)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n, random_state=seed, shuffle=True)\n",
    "                min_max_scaler = MinMaxScaler()\n",
    "                min_max_scaler.fit(X_train)\n",
    "                X_train = min_max_scaler.transform(X_train)\n",
    "                X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "                key = str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_Ytrue\")\n",
    "                predictions[key] = y_test\n",
    "                \n",
    "                for reg in args.estimators:    \n",
    "                    estimator = load_estimator(str(\"seed\" + str(seed) + \"_subset\" + str(subset) + \"_n\" + str(n) + \"_\" + reg))\n",
    "                    estimator_name = str(estimator)[:str(estimator).index('(')]\n",
    "                    print(\"\\n\", estimator_name)\n",
    "\n",
    "                    y_pred, fit_time = train_and_test_whole(estimator, X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    key = str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_\" + estimator_name + \"_Ypred\")\n",
    "                    predictions[key] = y_pred\n",
    "                    fit_times[estimator_name].append(fit_time)\n",
    "\n",
    "        #one file per n\n",
    "        save_results(predictions, n, \"nasbench_predictions\")\n",
    "        save_results(fit_times, n, \"nasbench_fit_times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assigned-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path:  /home/gean/Code/nns_performance_prediction/meta_datasets/\n",
      "model_path:  /home/gean/Code/nns_performance_prediction/saved_models/fast/test1/\n",
      "results_path:  /home/gean/Code/nns_performance_prediction/saved_models/fast/test1/\n",
      "target:  final_validation_accuracy\n",
      "data_subset:  [4, 12, 36, 108]\n",
      "seed:  [0, 42]\n",
      "train_size:  [43, 86, 129, 172, 344, 860]\n",
      "estimators:  ['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor', 'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', 'DummyRegressor']\n",
      "features drop:  ['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', 'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy']\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 4 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 12 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 36 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 108 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 4 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 12 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 36 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 108 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 4 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 12 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 36 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 108 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 4 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 12 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 36 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 108 , N 86\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-394b3f21dc1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features drop: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mextract_predictions_and_fittime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3884c285ce83>\u001b[0m in \u001b[0;36mextract_predictions_and_fittime\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test_whole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Seed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_Subset\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_N\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mestimator_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_Ypred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f61e54ed996f>\u001b[0m in \u001b[0;36mtrain_and_test_whole\u001b[0;34m(estimator, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing DONE\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m   1381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    697\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    698\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# For the hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# For the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_base.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path: \", args.data_path)\n",
    "    print(\"model_path: \", args.model_path)\n",
    "    print(\"results_path: \", args.results_path)\n",
    "    print(\"target: \", args.target)\n",
    "    print(\"data_subset: \", args.data_subset)\n",
    "    print(\"seed: \", args.seed)\n",
    "    print(\"train_size: \", args.train_size)                \n",
    "    print(\"estimators: \", args.estimators)\n",
    "    print(\"features drop: \", args.features_drop)\n",
    "\n",
    "    extract_predictions_and_fittime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-insert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
