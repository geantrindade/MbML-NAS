{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "congressional-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "local-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/Code/nns_performance_prediction/meta_datasets/', help='location of the dataset')    \n",
    "parser.add_argument('--model_path', type=str, default='/home/gean/Code/nns_performance_prediction/saved_models/fast/test1/', help='path to save the trained models')\n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/Code/nns_performance_prediction/results/fast/test1/', help='location of the results directory')    \n",
    "parser.add_argument('--target', type=str, default='final_validation_accuracy', help='target of the training/test')\n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 12], help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "parser.add_argument('--seed', type=int, default=[0, 42], nargs='+', help='seeds used for all the random procedures') \n",
    "parser.add_argument('--train_size', type=int, default=[43, 86], help='[Int, Int...] representing the total number of train samples')\n",
    "\n",
    "parser.add_argument('--estimators', type=str, default=['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor',\n",
    "                                                       'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', \n",
    "                                                       'DummyRegressor'], nargs='+', help='list of sklearn estimators to be used for training') \n",
    "\n",
    "#final_test_accuracy included for extraction purposes\n",
    "parser.add_argument('--features_drop', type=str, default=[], nargs='+', help='list of features to drop from nasbench101')\n",
    "\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "false-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_numpy_dataset(data_subset):\n",
    "    dtype = {\"module_adjacency\": 'object', \"module_operations\": 'object', \"trainable_parameters\": 'uint8', \"conv_num_layers\": 'uint8', \"conv_kernel_min\": 'uint8', \n",
    "             \"conv_kernel_max\": 'uint8', \"conv_kernel_mode\": 'uint8', \"maxpool_num_layers\": 'uint8', \"final_validation_accuracy\": 'float16', \"final_test_accuracy\": 'float16'}    \n",
    "                 \n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench101_' + str(data_subset) + 'epochs_tabular.csv'), dtype=dtype, usecols=[\"module_adjacency\", \"module_operations\", \n",
    "                            \"trainable_parameters\", \"conv_num_layers\", \"conv_kernel_min\", \"conv_kernel_max\", \"conv_kernel_mode\", \"maxpool_num_layers\", \n",
    "                            \"final_validation_accuracy\", \"final_test_accuracy\"])\n",
    "    df_whole.drop(args.features_drop, axis=1, inplace=True)\n",
    "    print(df_whole.dtypes)\n",
    "    \n",
    "    df_whole = pd.get_dummies(df_whole)\n",
    "    df_y = df_whole[args.target]\n",
    "    df_X = df_whole.drop([args.target], axis = 1)\n",
    "    X = df_X.to_numpy()\n",
    "    y = df_y.to_numpy()\n",
    "    df_whole = None\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aquatic-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_time_extraction(estimator, X_train, y_train, X_test, y_test):\n",
    "    tic = time.time()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    toc = time.time()\n",
    "    print(\"Training DONE\")\n",
    "    \n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"Testing DONE\\n\")\n",
    "    \n",
    "    return y_pred, (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imperial-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator(file_name: str):\n",
    "    estimator = load(str(args.model_path + file_name + '.joblib'))\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arbitrary-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(performance_dict, subset, file_name): \n",
    "    df_results = pd.DataFrame.from_dict(performance_dict)\n",
    "    df_results.to_csv(str(args.results_path + \"Subset\" + str(subset) + \"_\" + file_name + '.csv'),\n",
    "                      index=False, float_format='%.6f')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "departmental-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for subset in args.data_subset:\n",
    "        X, y = get_preprocessed_numpy_dataset(subset)\n",
    "\n",
    "        predictions = {}\n",
    "        fit_times = {'LinearRegression': [], 'SGDRegressor': [], 'Lasso': [], 'BayesianRidge': [], 'KNeighborsRegressor': [], 'DecisionTreeRegressor': [], 'SVR': [], \n",
    "                     'MLPRegressor': [], 'RandomForestRegressor': [], 'AdaBoostRegressor': [], 'GradientBoostingRegressor': [], 'DummyRegressor': []}\n",
    "        mae_values = {'LinearRegression_MAE': [], 'SGDRegressor_MAE': [], 'Lasso_MAE': [], 'BayesianRidge_MAE': [], 'KNeighborsRegressor_MAE': [], \n",
    "                      'DecisionTreeRegressor_MAE': [], 'SVR_MAE': [], 'MLPRegressor_MAE': [], 'RandomForestRegressor_MAE': [], 'AdaBoostRegressor_MAE': [], \n",
    "                      'GradientBoostingRegressor_MAE': [], 'DummyRegressor_MAE': []}        \n",
    "        mse_values = {'LinearRegression_MSE': [], 'SGDRegressor_MSE': [], 'Lasso_MSE': [], 'BayesianRidge_MSE': [], 'KNeighborsRegressor_MSE': [], \n",
    "                      'DecisionTreeRegressor_MSE': [], 'SVR_MSE': [], 'MLPRegressor_MSE': [], 'RandomForestRegressor_MSE': [], 'AdaBoostRegressor_MSE': [], \n",
    "                      'GradientBoostingRegressor_MSE': [], 'DummyRegressor_MSE': []}            \n",
    "        r2_values = {'LinearRegression_R2': [], 'SGDRegressor_R2': [], 'Lasso_R2': [], 'BayesianRidge_R2': [], 'KNeighborsRegressor_R2': [], \n",
    "                     'DecisionTreeRegressor_R2': [], 'SVR_R2': [], 'MLPRegressor_R2': [], 'RandomForestRegressor_R2': [], 'AdaBoostRegressor_R2': [], \n",
    "                     'GradientBoostingRegressor_R2': [], 'DummyRegressor_R2': []}\n",
    "        \n",
    "        for n in args.train_size:\n",
    "\n",
    "            for seed in args.seed:\n",
    "                set_default_seed(seed)\n",
    "                print(\"\\n\\n######### Seed{}, Subset{}, N{} #########\".format(seed, subset, n))\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n, random_state=seed, shuffle=True)\n",
    "                \n",
    "                X_train = np.delete(X_train, 1, axis=1) #del final_test_acc\n",
    "                final_test_acc = X_test[:, 1] #save final_test_acc\n",
    "                X_test = np.delete(X_test, 1, axis=1) #del final_test_acc\n",
    "                \n",
    "                min_max_scaler = MinMaxScaler()\n",
    "                min_max_scaler.fit(X_train)\n",
    "                X_train = min_max_scaler.transform(X_train)\n",
    "                X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "                predictions[str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_True_Test_Acc\")] = final_test_acc #final_test_acc\n",
    "                predictions[str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_True_Val_Acc\")] = y_test #final_val_acc\n",
    "                \n",
    "                for reg in args.estimators:    \n",
    "                    estimator = load_estimator(str(\"seed\" + str(seed) + \"_subset\" + str(subset) + \"_n\" + str(n) + \"_\" + reg))\n",
    "                    estimator_name = str(estimator)[:str(estimator).index('(')]\n",
    "                    print(\"\\n\", estimator_name)\n",
    "\n",
    "                    y_pred, fit_time = preds_time_extraction(estimator, X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    #save results in dicsts\n",
    "                    predictions[str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_\" + estimator_name + \"_Pred_Val_Acc\")] = y_pred                   \n",
    "                    fit_times[estimator_name].append(fit_time)                    \n",
    "\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    mae_values[str(reg + '_MAE')].append(mae)\n",
    "                    \n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    mse_values[str(reg + '_MSE')].append(mse)\n",
    "                    \n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "                    r2_values[str(reg + '_R2')].append(r2)\n",
    "                        \n",
    "        performance_metrics = {**mae_values, **mse_values, **r2_values}\n",
    "                    \n",
    "        #one file per 'subset' per 'n'\n",
    "        save_results(predictions, subset, \"nasbench_predictions\")\n",
    "        save_results(fit_times, subset, \"nasbench_fit_times\")\n",
    "        save_results(performance_metrics, subset, \"nasbench_metrics\")\n",
    "        print(\"\\n#########################################\")\n",
    "        print(\"####### Results for Subset{} GENERATED #######\".format(subset))\n",
    "        print(\"#########################################\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path:  /home/gean/Code/nns_performance_prediction/meta_datasets/\n",
      "model_path:  /home/gean/Code/nns_performance_prediction/saved_models/fast/test1/\n",
      "results_path:  /home/gean/Code/nns_performance_prediction/results/fast/test1/\n",
      "target:  final_validation_accuracy\n",
      "data_subset:  [4, 12]\n",
      "seed:  [0, 42]\n",
      "train_size:  [43, 86]\n",
      "estimators:  ['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor', 'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', 'DummyRegressor']\n",
      "features drop:  []\n",
      "module_adjacency              object\n",
      "module_operations             object\n",
      "trainable_parameters           uint8\n",
      "final_validation_accuracy    float16\n",
      "final_test_accuracy          float16\n",
      "conv_num_layers                uint8\n",
      "conv_kernel_min                uint8\n",
      "conv_kernel_max                uint8\n",
      "conv_kernel_mode               uint8\n",
      "maxpool_num_layers             uint8\n",
      "dtype: object\n",
      "\n",
      "\n",
      "######### Seed0, Subset4, N43 #########\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path: \", args.data_path)\n",
    "    print(\"model_path: \", args.model_path)\n",
    "    print(\"results_path: \", args.results_path)\n",
    "    print(\"target: \", args.target)\n",
    "    print(\"data_subset: \", args.data_subset)\n",
    "    print(\"seed: \", args.seed)\n",
    "    print(\"train_size: \", args.train_size)                \n",
    "    print(\"estimators: \", args.estimators)\n",
    "    print(\"features drop: \", args.features_drop)\n",
    "\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-interim",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
