{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/Code/nns_performance_prediction/meta_datasets/', help='location of the dataset')    \n",
    "parser.add_argument('--model_path', type=str, default='/home/gean/Code/nns_performance_prediction/saved_models/fast/test1/', help='path to save the trained models')\n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/Code/nns_performance_prediction/results/fast/test1/', help='location of the results directory')    \n",
    "parser.add_argument('--target', type=str, default='final_validation_accuracy', help='target of the training/test')\n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 12, 36, 108], help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "parser.add_argument('--seed', type=int, default=[0, 42], nargs='+', help='seeds used for all the random procedures') \n",
    "parser.add_argument('--train_size', type=int, default=[43], help='[Int, Int...] representing the total number of train samples')\n",
    "\n",
    "parser.add_argument('--estimators', type=str, default=['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor',\n",
    "                                                       'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', \n",
    "                                                       'DummyRegressor'], nargs='+', help='list of sklearn estimators to be used for training') \n",
    "\n",
    "parser.add_argument('--features_drop', type=str, default=['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', \n",
    "                                                          'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy'], \n",
    "                    nargs='+', help='list of features to drop from nasbench101')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moderate-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dietary-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_numpy_dataset(data_subset):\n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench101_' + str(data_subset) + 'epochs_tabular.csv'))\n",
    "    df_whole.drop(args.features_drop, axis=1, inplace=True)\n",
    "    df_whole = pd.get_dummies(df_whole)\n",
    "    \n",
    "    df_y = df_whole[args.target]\n",
    "    df_X = df_whole.drop([args.target], axis = 1)\n",
    "    X = df_X.to_numpy()\n",
    "    y = df_y.to_numpy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incredible-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fit_time_from_train(estimator, X_train, y_train, X_test, y_test):\n",
    "    tic = time.time()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    toc = time.time()\n",
    "    print(\"Training DONE\")\n",
    "      \n",
    "    return (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romance-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator(file_name: str):\n",
    "    estimator = load(str(args.model_path + file_name + '.joblib'))\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "third-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(performance_dict, n, file_name): \n",
    "    df_results = pd.DataFrame.from_dict(performance_dict)\n",
    "    df_results.to_csv(str(args.results_path + \"N\" + str(n) + \"_\" + file_name + '.csv'),\n",
    "                      index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "behind-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fittime():\n",
    "    for n in args.train_size:\n",
    "        fit_times = {'LinearRegression': [], 'SGDRegressor': [], 'Lasso': [], 'BayesianRidge': [], 'KNeighborsRegressor': [], 'DecisionTreeRegressor': [], 'SVR': [], \n",
    "                     'MLPRegressor': [], 'RandomForestRegressor': [], 'AdaBoostRegressor': [], 'GradientBoostingRegressor': [], 'DummyRegressor': []}\n",
    "\n",
    "        for seed in args.seed:\n",
    "            set_default_seed(seed)\n",
    "\n",
    "            for subset in args.data_subset:\n",
    "                X, y = get_preprocessed_numpy_dataset(subset)\n",
    "                print(\"\\n\\n######### Seed\", seed, \", Subset\", subset, \", N\", n)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n, random_state=seed, shuffle=True)\n",
    "                min_max_scaler = MinMaxScaler()\n",
    "                min_max_scaler.fit(X_train)\n",
    "                X_train = min_max_scaler.transform(X_train)\n",
    "                X_test = min_max_scaler.transform(X_test)\n",
    "        \n",
    "                for reg in args.estimators:    \n",
    "                    estimator = load_estimator(str(\"seed\" + str(seed) + \"_subset\" + str(subset) + \"_n\" + str(n) + \"_\" + reg))\n",
    "                    estimator_name = str(estimator)[:str(estimator).index('(')]\n",
    "                    print(\"\\n\", estimator_name)\n",
    "\n",
    "                    fit_time = extract_fit_time_from_train(estimator, X_train, y_train, X_test, y_test)\n",
    "                    fit_times[estimator_name].append(fit_time)\n",
    "\n",
    "        #one file per n\n",
    "        save_results(fit_times, n, \"nasbench_fit_times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greater-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path:  /home/gean/Code/nns_performance_prediction/meta_datasets/\n",
      "model_path:  /home/gean/Code/nns_performance_prediction/saved_models/fast/test1/\n",
      "results_path:  /home/gean/Code/nns_performance_prediction/results/fast/test1/\n",
      "target:  final_validation_accuracy\n",
      "data_subset:  [4, 12, 36, 108]\n",
      "seed:  [0, 42]\n",
      "train_size:  [43]\n",
      "estimators:  ['LinearRegression', 'SGDRegressor', 'Lasso', 'BayesianRidge', 'KNeighborsRegressor', 'DecisionTreeRegressor', 'SVR', 'MLPRegressor', 'RandomForestRegressor', 'AdaBoostRegressor', 'GradientBoostingRegressor', 'DummyRegressor']\n",
      "features drop:  ['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', 'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy']\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 4 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 12 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 36 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 108 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 4 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 12 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 36 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n",
      "\n",
      "\n",
      "######### Seed 42 , Subset 108 , N 43\n",
      "\n",
      " LinearRegression\n",
      "Training DONE\n",
      "\n",
      " SGDRegressor\n",
      "Training DONE\n",
      "\n",
      " Lasso\n",
      "Training DONE\n",
      "\n",
      " BayesianRidge\n",
      "Training DONE\n",
      "\n",
      " KNeighborsRegressor\n",
      "Training DONE\n",
      "\n",
      " DecisionTreeRegressor\n",
      "Training DONE\n",
      "\n",
      " SVR\n",
      "Training DONE\n",
      "\n",
      " MLPRegressor\n",
      "Training DONE\n",
      "\n",
      " RandomForestRegressor\n",
      "Training DONE\n",
      "\n",
      " AdaBoostRegressor\n",
      "Training DONE\n",
      "\n",
      " GradientBoostingRegressor\n",
      "Training DONE\n",
      "\n",
      " DummyRegressor\n",
      "Training DONE\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path: \", args.data_path)\n",
    "    print(\"model_path: \", args.model_path)\n",
    "    print(\"results_path: \", args.results_path)\n",
    "    print(\"target: \", args.target)\n",
    "    print(\"data_subset: \", args.data_subset)\n",
    "    print(\"seed: \", args.seed)\n",
    "    print(\"train_size: \", args.train_size)                \n",
    "    print(\"estimators: \", args.estimators)\n",
    "    print(\"features drop: \", args.features_drop)\n",
    "\n",
    "    extract_fittime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
