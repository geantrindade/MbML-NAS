{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "willing-freight",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opposite-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-eugene",
   "metadata": {},
   "source": [
    "## Command-line Arguments Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thick-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/Code/nns_performance_prediction/meta_datasets/', help='location of the dataset')    \n",
    "parser.add_argument('--model_path', type=str, default='/home/gean/Code/nns_performance_prediction/saved_models/', help='path to save the trained models')\n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/Code/nns_performance_prediction/results/', help='location of the results directory')    \n",
    "parser.add_argument('--target', type=str, default='final_validation_accuracy', help='target of the training/test')\n",
    "parser.add_argument('--n_iter_rs', type=int, default=2, help='number of iterations for random search')\n",
    "parser.add_argument('--cv_inner', type=int, default=3, help='number of partitions for the inner split of nested cross-validation')\n",
    "parser.add_argument('--scoring_rs', type=str, default=None, help='[neg_mean_absolute_error, neg_mean_squared_error, r2, None]')\n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "# parser.add_argument('--data_subset', type=int, default=[4, 12], nargs='+', help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 12, 36, 108], nargs='+', help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "# parser.add_argument('--seed', type=int, default=[0, 1], nargs='+', help='seeds used for all the random procedures') \n",
    "parser.add_argument('--seed', type=int, default=[0, 1, 10, 42, 100, 123, 666, 1000, 1234, 12345], nargs='+', help='seeds used for all the random procedures') \n",
    "# parser.add_argument('--train_size', type=int, default=[43, 86], nargs='+', help='[Int, Int...] representing the total number of train samples')\n",
    "parser.add_argument('--train_size', type=int, default=[43, 86, 129, 172, 344, 860], nargs='+', help='[Int, Int...] representing the total number of train samples')\n",
    "# parser.add_argument('--estimators', type=str, default=['linear_regression', 'sgd', 'lasso', 'bayesian_ridge', 'knn', 'dt', 'svm', 'mlp', 'random_forest', \n",
    "#                                                     'ada_boost', 'gradient_boost', 'dummy'], nargs='+', help='list of sklearn estimators to be used for training') \n",
    "#except mlp (expansive) and lasso (much similar to dummy)\n",
    "parser.add_argument('--estimators', type=str, default=['linear_regression', 'sgd', 'bayesian_ridge', 'knn', 'dt', 'svm', 'random_forest', \n",
    "                                                    'ada_boost', 'gradient_boost', 'dummy'], nargs='+', help='list of sklearn estimators to be used for training') \n",
    "\n",
    "parser.add_argument('--features_drop', type=str, default=['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', \n",
    "                                                          'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy'], \n",
    "                                                nargs='+', help='list of features to drop from nasbench101')\n",
    "\n",
    "#args = parser.parse_args(args=[])\n",
    "args, unknown = parser.parse_known_args() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-tuition",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fundamental-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "heated-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_numpy_dataset(data_subset):\n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench101_' + str(data_subset) + 'epochs_tabular.csv'))\n",
    "    df_whole.drop(args.features_drop, axis=1, inplace=True)\n",
    "    df_whole = pd.get_dummies(df_whole)\n",
    "    \n",
    "    df_y = df_whole[args.target]\n",
    "    df_X = df_whole.drop([args.target], axis = 1)\n",
    "    X = df_X.to_numpy()\n",
    "    y = df_y.to_numpy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worthy-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators(seed):\n",
    "    estimators_case_insensitive = [el.lower() for el in args.estimators]\n",
    "    estimators = []\n",
    "    \n",
    "    if (\"linear_regression\" in estimators_case_insensitive):\n",
    "        estimators.append(LinearRegression(n_jobs=-1))\n",
    "    \n",
    "    if (\"sgd\" in estimators_case_insensitive):\n",
    "        estimators.append(SGDRegressor(random_state=seed))\n",
    "        \n",
    "#     if (\"lasso\" in estimators_case_insensitive):\n",
    "#         estimators.append(Lasso(random_state=seed))\n",
    "    \n",
    "    if (\"bayesian_ridge\" in estimators_case_insensitive):\n",
    "        estimators.append(BayesianRidge())\n",
    "\n",
    "    if (\"knn\" in estimators_case_insensitive):\n",
    "        estimators.append(KNeighborsRegressor(n_jobs=-1))\n",
    "    \n",
    "    if (\"dt\" in estimators_case_insensitive):\n",
    "        estimators.append(DecisionTreeRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"svm\" in estimators_case_insensitive):\n",
    "        estimators.append(SVR())\n",
    "        \n",
    "#     if (\"mlp\" in estimators_case_insensitive):\n",
    "#         estimators.append(MLPRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"random_forest\" in estimators_case_insensitive):\n",
    "        estimators.append(RandomForestRegressor(n_jobs=-1, random_state=seed))\n",
    "        \n",
    "    if (\"ada_boost\" in estimators_case_insensitive):\n",
    "        estimators.append(AdaBoostRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"gradient_boost\" in estimators_case_insensitive):\n",
    "        estimators.append(GradientBoostingRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"dummy\" in estimators_case_insensitive):\n",
    "        estimators.append(DummyRegressor())\n",
    "    \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beginning-export",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_estimators_hyperparameters_to_search():\n",
    "    #linear regression\n",
    "    hp_lr = {'fit_intercept': [False, True],\n",
    "        'normalize': [False, True]}\n",
    "\n",
    "    #stochastic gradient descent\n",
    "    hp_sgd = {'loss': [\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "         'penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
    "         'fit_intercept': [False, True],\n",
    "         'max_iter': [1000, 3000, 9000],\n",
    "         'shuffle': [False, True],\n",
    "         'learning_rate': [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "         'early_stopping': [False, True],\n",
    "         'n_iter_no_change': [5, 15, 45],\n",
    "         'warm_start': [False, True]}\n",
    "    \n",
    "    #lasso\n",
    "#     hp_lasso = {'fit_intercept': [False, True],\n",
    "#             'normalize': [False, True],\n",
    "#            'max_iter': [1000, 3000, 9000],\n",
    "#            'warm_start': [False, True],\n",
    "#            'positive': [False, True],\n",
    "#            'selection': [\"cyclic\", \"random\"],\n",
    "#             'tol': [0.001, 0.0001, 0.00001]}\n",
    "    \n",
    "    #bayesian ridge\n",
    "    hp_bayesian = {'n_iter': [1000, 3000, 9000],\n",
    "              'tol': [0.001, 0.0001, 0.00001],\n",
    "              'compute_score': [False, True],\n",
    "              'fit_intercept': [False, True],\n",
    "                  'normalize': [False, True]}\n",
    "\n",
    "    #k-nearest neighbors\n",
    "    hp_knn = {'n_neighbors': list(range(1, 26)),\n",
    "              'weights': [\"uniform\", \"distance\"],\n",
    "         'algorithm': [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "         'leaf_size': [30, 90, 270],\n",
    "         'p': [1, 2]}\n",
    "\n",
    "    #decision tree\n",
    "    hp_dt = {'criterion': [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "        'splitter': [\"best\", \"random\"],\n",
    "        'max_depth': list(range(2, 51)) + [None],\n",
    "        'min_samples_split': list(range(2, 51)),\n",
    "        'min_samples_leaf': list(range(1, 51)),\n",
    "        'max_features': [\"auto\", \"sqrt\", \"log2\"]}\n",
    "    \n",
    "    #support vector machine\n",
    "    hp_svr = {'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "         'gamma': [\"scale\", \"auto\"],\n",
    "         'C': list(range(1, 51)),\n",
    "         'max_iter': [1000, 3000, 9000]}\n",
    "\n",
    "    #multilayer perceptron or feed-forward neural network\n",
    "#     hp_mlp = {'hidden_layer_sizes': [(np.random.randint(1, 900),), (np.random.randint(1, 900), np.random.randint(1, 900)), \n",
    "#                                      (np.random.randint(1, 900), np.random.randint(1, 900), np.random.randint(1, 900))],\n",
    "#          'activation': [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "#          'solver': [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "#          'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "#          'learning_rate_init': [0.01, 0.001, 0.0001],\n",
    "#          'max_iter': [1000, 3000, 9000],\n",
    "#          'warm_start': [False, True],\n",
    "#          'momentum': np.random.uniform(low=0.0, high=1.0, size=50),\n",
    "#          'nesterovs_momentum': [False, True],\n",
    "#          'early_stopping': [False, True],\n",
    "#          'n_iter_no_change': [10, 30, 90],\n",
    "#          'max_fun': [15000, 45000, 135000]}\n",
    "\n",
    "    #random forest\n",
    "    hp_random_forest = {'n_estimators': [100, 300, 900],\n",
    "                   'criterion': [\"mse\", \"mae\"],\n",
    "                   'min_samples_split': list(range(2, 51)),\n",
    "                   'min_samples_leaf': list(range(1, 51)),\n",
    "                   'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "                   'oob_score': [False, True],\n",
    "                   'warm_start': [False, True]}                   \n",
    "\n",
    "    #ada boosting\n",
    "    hp_ada_boost = {'n_estimators': [50, 150, 450],\n",
    "               'learning_rate': [1, 0.1, 0.01],\n",
    "               'loss': [\"linear\", \"square\", \"exponential\"]}\n",
    "\n",
    "    #gradient boosting\n",
    "    hp_gradient_boost = {'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                     'learning_rate': [0.1, 0.01, 0.001],\n",
    "                     'n_estimators': [100, 300, 900],\n",
    "                     'subsample': [0.1, 0.5, 1.0],\n",
    "                     'criterion': [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "                     'min_samples_split': list(range(2, 51)),\n",
    "                     'min_samples_leaf': list(range(1, 51)),\n",
    "                     'max_depth': list(range(3, 51)),\n",
    "                     'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "                     'warm_start': [False, True], \n",
    "                     'n_iter_no_change': [10, 30, 90, None]}\n",
    "\n",
    "    #simple rule regressor\n",
    "    hp_dummy = {'strategy': [\"mean\", \"median\", \"quantile\"], \n",
    "            'quantile': [0.0, 0.25, 0.75, 1.0]}\n",
    "    \n",
    "    return hp_lr, hp_sgd, hp_lasso, hp_bayesian, hp_knn, hp_dt, hp_svr, hp_mlp, hp_random_forest, hp_ada_boost, hp_gradient_boost, hp_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "practical-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator, file_name : str):\n",
    "    dump(estimator, str(args.model_path + file_name + '.joblib')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "juvenile-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator(file_name: str):\n",
    "    estimator = load(str(args.model_path + file_name + '.joblib'))\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "chinese-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_whole(estimator, X_train, y_train, X_test, y_test):\n",
    "    tic = time.time()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    toc = time.time()\n",
    "    print(\"Training DONE\")\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"Testing DONE\\n\\n\")\n",
    "    \n",
    "    return y_pred, (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coupled-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(performance_dict, n, file_name): \n",
    "    df_results = pd.DataFrame.from_dict(performance_dict)\n",
    "    df_results.to_csv(str(args.results_path + \"N\" + str(n) + \"_\" + file_name + '.csv'),\n",
    "                      index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-universal",
   "metadata": {},
   "source": [
    "## Train/Val/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-graduation",
   "metadata": {},
   "source": [
    "### RandomSearch with 3-Folds and Train/Test with Hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "massive-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for n in args.train_size:\n",
    "        predictions = {}\n",
    "#         fit_times = {'LinearRegression': [], 'SGDRegressor': [], 'Lasso': [], 'BayesianRidge': [], 'KNeighborsRegressor': [], 'DecisionTreeRegressor': [], 'SVR': [], \n",
    "#                      'MLPRegressor': [], 'RandomForestRegressor': [], 'AdaBoostRegressor': [], 'GradientBoostingRegressor': [], 'DummyRegressor': []}\n",
    "        fit_times = {'LinearRegression': [], 'SGDRegressor': [], 'BayesianRidge': [], 'KNeighborsRegressor': [], 'DecisionTreeRegressor': [], 'SVR': [], \n",
    "                     'RandomForestRegressor': [], 'AdaBoostRegressor': [], 'GradientBoostingRegressor': [], 'DummyRegressor': []}\n",
    "    \n",
    "        for seed in args.seed:\n",
    "            set_default_seed(seed)\n",
    "        \n",
    "            for subset in args.data_subset:\n",
    "                X, y = get_preprocessed_numpy_dataset(subset)\n",
    "                print(\"\\n\\n######### Seed\", seed, \", Subset\", subset, \", N\", n)\n",
    "            \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n, random_state=seed, shuffle=True)\n",
    "\n",
    "                min_max_scaler = MinMaxScaler()\n",
    "                min_max_scaler.fit(X_train)\n",
    "                X_train = min_max_scaler.transform(X_train)\n",
    "                X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "                key = str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_Ytrue\")\n",
    "                predictions[key] = y_test\n",
    "                \n",
    "                estimators = get_estimators(seed)\n",
    "                hyperparameters = get_estimators_hyperparameters_to_search()\n",
    "                \n",
    "                for reg, hp in zip(estimators, hyperparameters):\n",
    "                    rs = RandomizedSearchCV(estimator=reg, param_distributions=hp, n_iter=args.n_iter_rs, scoring=args.scoring_rs, \n",
    "                                            n_jobs=-1, cv=args.cv_inner, verbose=0, pre_dispatch='2*n_jobs', random_state=seed)\n",
    "\n",
    "                    reg_name = str(reg)[:str(reg).index('(')]\n",
    "                    print(\"\\n#\", reg_name, \"#\")\n",
    "                    \n",
    "                    print(\"\\n#########\", args.cv_inner, \"Fold RANDOM SEARCH #########\")\n",
    "                    rs.fit(X_train, y_train) \n",
    "                    print(\"DONE\")\n",
    "                    \n",
    "                    best_estimator = rs.best_estimator_\n",
    "                    print(\"best estimator: \", best_estimator.get_params())\n",
    "                    \n",
    "                    print(\"\\n######### HOLD-OUT VALIDATION #########\")\n",
    "                    y_pred, fit_time = train_and_test_whole(best_estimator, X_train, y_train, X_test, y_test)\n",
    "                    \n",
    "                    key = str('Seed' + str(seed) + \"_Subset\" + str(subset) + \"_N\" + str(n) + \"_\" + reg_name + \"_Ypred\")\n",
    "                    predictions[key] = y_pred\n",
    "                    fit_times[reg_name].append(fit_time)\n",
    "                    \n",
    "#                     save_estimator(best_estimator, str(\"seed\" + str(seed) + \"_subset\" + str(subset) + \"_n\" + str(n) + \"_\" + reg_name))    \n",
    "                    \n",
    "#         save_results(predictions, n, \"nasbench_predictions\")\n",
    "        save_results(fit_times, n, \"nasbench_fit_times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-interest",
   "metadata": {},
   "source": [
    "### Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "desirable-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path:  /home/gean/Code/nns_performance_prediction/meta_datasets/\n",
      "model_path:  /home/gean/Code/nns_performance_prediction/saved_models/\n",
      "results_path:  /home/gean/Code/nns_performance_prediction/results/\n",
      "target:  final_validation_accuracy\n",
      "n_iter_rs:  2\n",
      "cv_inner:  3\n",
      "scoring_rs:  None\n",
      "data_subset:  [4, 12]\n",
      "seed:  [0, 1]\n",
      "train_size:  [43, 86]\n",
      "estimators:  ['linear_regression', 'sgd', 'lasso', 'bayesian_ridge', 'knn', 'dt', 'svm', 'mlp', 'random_forest', 'ada_boost', 'gradient_boost', 'dummy']\n",
      "features drop:  ['module_adjacency', 'halfway_training_time', 'halfway_train_accuracy', 'halfway_validation_accuracy', 'halfway_test_accuracy', 'final_training_time', 'final_train_accuracy', 'final_test_accuracy']\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 4 , N 43\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 2, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 47, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 29, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (560, 630), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 45000, 'max_iter': 9000, 'momentum': 0.6120957227224214, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 1, 'loss': 'linear', 'n_estimators': 450, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 12 , N 43\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 29, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (847, 144, 661), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6778165367962301, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 46, 'min_samples_split': 20, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 1, 'loss': 'linear', 'n_estimators': 450, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 36, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 29, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 1 , Subset 4 , N 43\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 45, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.8781174363909454, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 14, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 32, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 1 , Subset 12 , N 43\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (794,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.029801358182393267, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 14, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 32, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 4 , N 86\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 29, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (560, 630), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 45000, 'max_iter': 9000, 'momentum': 0.6120957227224214, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 0 , Subset 12 , N 86\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 24, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (847, 144, 661), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6778165367962301, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 1, 'loss': 'linear', 'n_estimators': 450, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 1 , Subset 4 , N 86\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 45, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.4191945144032948, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 44, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######### Seed 1 , Subset 12 , N 86\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'C': 45, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (794,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.029801358182393267, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 44, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator:  {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path: \", args.data_path)\n",
    "    print(\"model_path: \", args.model_path)\n",
    "    print(\"results_path: \", args.results_path)\n",
    "    print(\"target: \", args.target)\n",
    "    print(\"n_iter_rs: \", args.n_iter_rs)\n",
    "    print(\"cv_inner: \", args.cv_inner)\n",
    "    print(\"scoring_rs: \", args.scoring_rs)\n",
    "    print(\"data_subset: \", args.data_subset)\n",
    "    print(\"seed: \", args.seed)\n",
    "    print(\"train_size: \", args.train_size)                \n",
    "    print(\"estimators: \", args.estimators)\n",
    "    print(\"features drop: \", args.features_drop)\n",
    "    \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-thread",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
