{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/nns_performance_prediction/results/fast/test12/', \n",
    "                    help='location of the dataset')    \n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/nns_performance_prediction/results/fast/test12/', \n",
    "                    help='location of the results directory')    \n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "parser.add_argument('--dataset', type=str, default=['cifar10valid', 'cifar100', 'imagenet16_120'], nargs='+', \n",
    "                    help='one of the datasets from nasbench201, being cifar10valid, cifar100, or imagenet16_120')\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 108, 200], \n",
    "                    help='one of the subsets from nasbench101 with 4, 12, 36, or 108 epochs')\n",
    "parser.add_argument('--train_size', type=int, default=[43, 86, 129, 172, 344, 860], \n",
    "                    help='[Int, Int...] representing the total number of train samples')\n",
    "#all except mlp\n",
    "parser.add_argument('--estimators', type=str, default=['LinearRegression', 'BayesianRidge', 'RandomForestRegressor', \n",
    "                                                       'GradientBoostingRegressor', 'DummyRegressor'], nargs='+',\n",
    "                    help='list of sklearn estimators used for training') \n",
    "parser.add_argument('--verbose', type=int, default=1, \n",
    "                    help='control the logging prints. 0 for deactivate and 1 for activate') \n",
    "\n",
    "args, unknown = parser.parse_known_args() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench201_allDatasets_allEpochs_allNs_metrics_absValues.csv'))\n",
    "    \n",
    "    for data in args.dataset:\n",
    "        for subset in args.data_subset:\n",
    "            for n in args.train_size:            \n",
    "                df_run = df_whole.loc[(df_whole['Dataset'] == str(data)) & \n",
    "                                      (df_whole['Epoch'] == int(subset)) & \n",
    "                                      (df_whole['Train_Size'] == int(n))]\n",
    "                \n",
    "                if len(df_run) == 0:\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    if args.verbose: \n",
    "                        print(\"=========== {}, Subset{}, N{} ===========\".format(data, subset, n))\n",
    "\n",
    "                    mae_nemenyi, mse_nemenyi = {}, {}\n",
    "\n",
    "                    for reg in args.estimators:\n",
    "                        reg_row = df_run.loc[(df_run['Model'] == str(reg))]\n",
    "                        mae_nemenyi[str(reg)] = list(reg_row['MAE'])\n",
    "                        mse_nemenyi[str(reg)] = list(reg_row['MSE'])\n",
    "\n",
    "                    df_mae_nemenyi = pd.DataFrame.from_dict(mae_nemenyi)\n",
    "                    df_mae_nemenyi = df_mae_nemenyi.rename(columns={\"LinearRegression\": \"Linear Regression\", \n",
    "                    \"SGDRegressor\": \"Stochastic Gradient Descent\", \"BayesianRidge\": \"Bayesian Ridge\",\n",
    "                    \"KNeighborsRegressor\": \"K-Nearest Neighbors\", \"DecisionTreeRegressor\": \"Decision Tree\",\n",
    "                    \"SVR\": \"Support Vector Machine\", \"RandomForestRegressor\": \"Random Forest\", \n",
    "                    \"AdaBoostRegressor\": \"AdaBoost\", \"GradientBoostingRegressor\": \"Gradient Boosting\", \n",
    "                    \"DummyRegressor\": \"Dummy\"})\n",
    "                \n",
    "                    df_mse_nemenyi = pd.DataFrame.from_dict(mse_nemenyi)\n",
    "                    df_mse_nemenyi = df_mse_nemenyi.rename(columns={\"LinearRegression\": \"Linear Regression\", \n",
    "                    \"SGDRegressor\": \"Stochastic Gradient Descent\", \"BayesianRidge\": \"Bayesian Ridge\",\n",
    "                    \"KNeighborsRegressor\": \"K-Nearest Neighbors\", \"DecisionTreeRegressor\": \"Decision Tree\",\n",
    "                    \"SVR\": \"Support Vector Machine\", \"RandomForestRegressor\": \"Random Forest\", \n",
    "                    \"AdaBoostRegressor\": \"AdaBoost\", \"GradientBoostingRegressor\": \"Gradient Boosting\", \n",
    "                    \"DummyRegressor\": \"Dummy\"})\n",
    "                    \n",
    "                    path = str(args.results_path + 'nasbench201_' + str(data) + '_' + str(subset) + 'epochs_n' + str(n))                                           \n",
    "                    df_mae_nemenyi.to_csv(str(path + '_mae_nemenyi.csv'), index=False, float_format='%.6f')\n",
    "                    df_mse_nemenyi.to_csv(str(path + '_mse_nemenyi.csv'), index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path: /home/gean/nns_performance_prediction/results/fast/test12/\n",
      "results_path: /home/gean/nns_performance_prediction/results/fast/test12/\n",
      "dataset: ['cifar10valid', 'cifar100', 'imagenet16_120']\n",
      "data_subset: [4, 108, 200]\n",
      "train_size: [43, 86, 129, 172, 344, 860]\n",
      "estimators: ['LinearRegression', 'BayesianRidge', 'RandomForestRegressor', 'GradientBoostingRegressor', 'DummyRegressor']\n",
      "verbose: 1\n",
      "=========== cifar10valid, Subset4, N43 ===========\n",
      "=========== cifar10valid, Subset4, N86 ===========\n",
      "=========== cifar10valid, Subset4, N129 ===========\n",
      "=========== cifar10valid, Subset4, N172 ===========\n",
      "=========== cifar10valid, Subset4, N344 ===========\n",
      "=========== cifar10valid, Subset4, N860 ===========\n",
      "=========== cifar10valid, Subset108, N43 ===========\n",
      "=========== cifar10valid, Subset108, N86 ===========\n",
      "=========== cifar10valid, Subset108, N129 ===========\n",
      "=========== cifar10valid, Subset108, N172 ===========\n",
      "=========== cifar10valid, Subset108, N344 ===========\n",
      "=========== cifar10valid, Subset108, N860 ===========\n",
      "=========== cifar10valid, Subset200, N43 ===========\n",
      "=========== cifar10valid, Subset200, N86 ===========\n",
      "=========== cifar10valid, Subset200, N129 ===========\n",
      "=========== cifar10valid, Subset200, N172 ===========\n",
      "=========== cifar10valid, Subset200, N344 ===========\n",
      "=========== cifar10valid, Subset200, N860 ===========\n",
      "=========== cifar100, Subset200, N43 ===========\n",
      "=========== cifar100, Subset200, N86 ===========\n",
      "=========== cifar100, Subset200, N129 ===========\n",
      "=========== cifar100, Subset200, N172 ===========\n",
      "=========== cifar100, Subset200, N344 ===========\n",
      "=========== cifar100, Subset200, N860 ===========\n",
      "=========== imagenet16_120, Subset200, N43 ===========\n",
      "=========== imagenet16_120, Subset200, N86 ===========\n",
      "=========== imagenet16_120, Subset200, N129 ===========\n",
      "=========== imagenet16_120, Subset200, N172 ===========\n",
      "=========== imagenet16_120, Subset200, N344 ===========\n",
      "=========== imagenet16_120, Subset200, N860 ===========\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path:\", args.data_path)\n",
    "    print(\"results_path:\", args.results_path)\n",
    "    print(\"dataset:\", args.dataset)\n",
    "    print(\"data_subset:\", args.data_subset)\n",
    "    print(\"train_size:\", args.train_size)\n",
    "    print(\"estimators:\", args.estimators)\n",
    "    print(\"verbose:\", args.verbose)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
