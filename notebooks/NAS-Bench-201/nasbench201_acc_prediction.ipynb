{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-line Arguments Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    " \n",
    "\n",
    "parser.add_argument('--data_path', type=str, default='/home/gean/nns_performance_prediction/meta_datasets/', \n",
    "                    help='location of the dataset')    \n",
    "parser.add_argument('--model_path', type=str, default='/home/gean/nns_performance_prediction/saved_models/', \n",
    "                    help='path to save the trained models')\n",
    "parser.add_argument('--results_path', type=str, default='/home/gean/nns_performance_prediction/results/fast/test12/', \n",
    "                    help='location of the results directory')    \n",
    "parser.add_argument('--target', type=str, default='acc_valid', \n",
    "                    help='target of the training/test')\n",
    "#default = 100\n",
    "parser.add_argument('--n_iter_rs', type=int, default=2,\n",
    "                    help='number of iterations for random search')\n",
    "parser.add_argument('--cv_inner', type=int, default=3,\n",
    "                    help='number of partitions for the inner split of nested cross-validation')\n",
    "#config fast/test12\n",
    "parser.add_argument('--scoring_rs', type=str, default='r2', \n",
    "                    help='[neg_mean_absolute_error, neg_mean_squared_error, r2, None]')\n",
    "\n",
    "#'+' == 1 or more, '*' == 0 or more, '?' == 0 or 1.\n",
    "# parser.add_argument('--dataset', type=str, default=['cifar10valid', 'cifar100', 'imagenet16_120'], nargs='+', \n",
    "parser.add_argument('--dataset', type=str, default=['imagenet16_120'], nargs='+', \n",
    "                    help='one of the datasets from nasbench201, being cifar10valid, cifar100, or imagenet16_120')\n",
    "#minimal efford\n",
    "parser.add_argument('--data_subset', type=int, default=[4, 108, 200], nargs='+', \n",
    "# parser.add_argument('--data_subset', type=int, default=[108, 200], nargs='+', \n",
    "                    help='one of the subsets from nasbench201 with 1, 4, 12, 36, 108, or 200 epochs')\n",
    "parser.add_argument('--seed', type=int, default=[0, 1, 10, 42, 100, 123, 666, 1000, 1234, 12345], nargs='+', \n",
    "# parser.add_argument('--seed', type=int, default=[0, 1], nargs='+', \n",
    "                    help='seeds used for all the random procedures') \n",
    "parser.add_argument('--train_size', type=int, default=[43, 86, 129, 172, 344, 860], nargs='+', \n",
    "# parser.add_argument('--train_size', type=int, default=[43, 86], nargs='+', \n",
    "                    help='[Int, Int...] representing the total number of train samples')\n",
    "parser.add_argument('--estimators', type=str, default=['linear_regression', 'sgd', 'lasso', 'bayesian_ridge', 'knn', 'dt', 'svm', \n",
    "                                                       'mlp', 'random_forest', 'ada_boost', 'gradient_boost', 'dummy'], nargs='+', \n",
    "                    help='list of sklearn estimators to be used for training') \n",
    "#remaining 'id_arch', 'conv_num_layers', 'conv_kernel_min', 'conv_kernel_max', 'conv_kernel_mode', 'avg_pool_num_layers'\n",
    "# 'params', 'acc_valid': 'acc_test'\n",
    "parser.add_argument('--features_drop', type=str, default=['str_arch', 'layers_all', 'adjacency_matrix', 'dataset', 'epoch', \n",
    "                                                          'skip_connection_num_layers', 'zeroize_num_layers', 'flops', 'latency', \n",
    "                                                          'time_train', 'time_valid', 'time_test', 'loss_train', 'loss_valid', \n",
    "                                                          'loss_test', 'acc_train'], nargs='+', \n",
    "                    help='list of features to drop from nasbench201')\n",
    "\n",
    "args, unknown = parser.parse_known_args() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_seed(seed, verbose=True):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if verbose: print(\"\\n###### set_default_seed() ######\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_numpy_dataset(dataset, data_subset, verbose=True):\n",
    "    df_whole = pd.read_csv(str(args.data_path + 'nasbench201_' + str(dataset) + '_' + str(data_subset) + 'epochs.csv'), index_col=0)\n",
    "    df_whole = df_whole.reset_index(drop=True)\n",
    "    df_whole.drop(args.features_drop, axis=1, inplace=True)\n",
    "\n",
    "    df_y = df_whole[args.target]\n",
    "    df_X = df_whole.drop([args.target], axis = 1)\n",
    "    X = df_X.to_numpy()\n",
    "    y = df_y.to_numpy()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"###### get_preprocessed_numpy_dataset() ######\")\n",
    "        print(\"df_whole after pre-processing:\", df_whole.head())\n",
    "        print(\"df_X:\", df_X.head(2))\n",
    "        print(\"df_y:\", df_y.head(2))\n",
    "        print(\"X numpy:\", X[:2])\n",
    "        print(\"X numpy shape:\", X.shape)\n",
    "        print(\"y numpy:\", y[:2])\n",
    "        print(\"y numpy shape:\", y.shape, \"\\n\")\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators(seed, verbose=True):\n",
    "    estimators_case_insensitive = [el.lower() for el in args.estimators]\n",
    "    estimators = []\n",
    "    \n",
    "    if (\"linear_regression\" in estimators_case_insensitive):\n",
    "        estimators.append(LinearRegression(n_jobs=-1))\n",
    "    \n",
    "    if (\"sgd\" in estimators_case_insensitive):\n",
    "        estimators.append(SGDRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"lasso\" in estimators_case_insensitive):\n",
    "        estimators.append(Lasso(random_state=seed))\n",
    "    \n",
    "    if (\"bayesian_ridge\" in estimators_case_insensitive):\n",
    "        estimators.append(BayesianRidge())\n",
    "\n",
    "    if (\"knn\" in estimators_case_insensitive):\n",
    "        estimators.append(KNeighborsRegressor(n_jobs=-1))\n",
    "    \n",
    "    if (\"dt\" in estimators_case_insensitive):\n",
    "        estimators.append(DecisionTreeRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"svm\" in estimators_case_insensitive):\n",
    "        estimators.append(SVR())\n",
    "        \n",
    "    if (\"mlp\" in estimators_case_insensitive):\n",
    "        estimators.append(MLPRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"random_forest\" in estimators_case_insensitive):\n",
    "        estimators.append(RandomForestRegressor(n_jobs=-1, random_state=seed))\n",
    "        \n",
    "    if (\"ada_boost\" in estimators_case_insensitive):\n",
    "        estimators.append(AdaBoostRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"gradient_boost\" in estimators_case_insensitive):\n",
    "        estimators.append(GradientBoostingRegressor(random_state=seed))\n",
    "        \n",
    "    if (\"dummy\" in estimators_case_insensitive):\n",
    "        estimators.append(DummyRegressor())\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"\\n###### get_estimators() ######\")\n",
    "        print(estimators, \"\\n\")\n",
    "    \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators_hyperparameters_to_search(verbose=True):\n",
    "    #linear regression\n",
    "    hp_lr = {'fit_intercept': [False, True],\n",
    "        'normalize': [False, True]}\n",
    "\n",
    "    #stochastic gradient descent\n",
    "    hp_sgd = {'loss': [\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "         'penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
    "         'fit_intercept': [False, True],\n",
    "         'max_iter': [1000, 3000, 9000],\n",
    "         'shuffle': [False, True],\n",
    "         'learning_rate': [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "         'early_stopping': [False, True],\n",
    "         'n_iter_no_change': [5, 15, 45],\n",
    "         'warm_start': [False, True]}\n",
    "    \n",
    "    #lasso\n",
    "    hp_lasso = {'fit_intercept': [False, True],\n",
    "            'normalize': [False, True],\n",
    "           'max_iter': [1000, 3000, 9000],\n",
    "           'warm_start': [False, True],\n",
    "           'positive': [False, True],\n",
    "           'selection': [\"cyclic\", \"random\"],\n",
    "            'tol': [0.001, 0.0001, 0.00001]}\n",
    "    \n",
    "    #bayesian ridge\n",
    "    hp_bayesian = {'n_iter': [1000, 3000, 9000],\n",
    "              'tol': [0.001, 0.0001, 0.00001],\n",
    "              'compute_score': [False, True],\n",
    "              'fit_intercept': [False, True],\n",
    "                  'normalize': [False, True]}\n",
    "\n",
    "    #k-nearest neighbors\n",
    "    hp_knn = {'n_neighbors': list(range(1, 26)),\n",
    "              'weights': [\"uniform\", \"distance\"],\n",
    "         'algorithm': [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "         'leaf_size': [30, 90, 270],\n",
    "         'p': [1, 2]}\n",
    "\n",
    "    #decision tree\n",
    "    hp_dt = {'criterion': [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "        'splitter': [\"best\", \"random\"],\n",
    "        'max_depth': list(range(2, 51)) + [None],\n",
    "        'min_samples_split': list(range(2, 51)),\n",
    "        'min_samples_leaf': list(range(1, 51)),\n",
    "        'max_features': [\"auto\", \"sqrt\", \"log2\"]}\n",
    "    \n",
    "    #support vector machine\n",
    "    hp_svr = {'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "         'gamma': [\"scale\", \"auto\"],\n",
    "         'C': list(range(1, 51)),\n",
    "         'max_iter': [1000, 3000, 9000]}\n",
    "\n",
    "    #multilayer perceptron or feed-forward neural network\n",
    "    hp_mlp = {'hidden_layer_sizes': [(np.random.randint(1, 900),), (np.random.randint(1, 900), np.random.randint(1, 900)), \n",
    "                                     (np.random.randint(1, 900), np.random.randint(1, 900), np.random.randint(1, 900))],\n",
    "         'activation': [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "         'solver': [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "         'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "         'learning_rate_init': [0.01, 0.001, 0.0001],\n",
    "         'max_iter': [1000, 3000, 9000],\n",
    "         'warm_start': [False, True],\n",
    "         'momentum': np.random.uniform(low=0.0, high=1.0, size=50),\n",
    "         'nesterovs_momentum': [False, True],\n",
    "         'early_stopping': [False, True],\n",
    "         'n_iter_no_change': [10, 30, 90],\n",
    "         'max_fun': [15000, 45000, 135000]}\n",
    "\n",
    "    #random forest\n",
    "    hp_random_forest = {'n_estimators': [100, 300, 900],\n",
    "                   'criterion': [\"mse\", \"mae\"],\n",
    "                   'min_samples_split': list(range(2, 51)),\n",
    "                   'min_samples_leaf': list(range(1, 51)),\n",
    "                   'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "                   'oob_score': [False, True],\n",
    "                   'warm_start': [False, True]}                   \n",
    "\n",
    "    #ada boosting\n",
    "    hp_ada_boost = {'n_estimators': [50, 150, 450],\n",
    "               'learning_rate': [1, 0.1, 0.01],\n",
    "               'loss': [\"linear\", \"square\", \"exponential\"]}\n",
    "\n",
    "    #gradient boosting\n",
    "    hp_gradient_boost = {'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                     'learning_rate': [0.1, 0.01, 0.001],\n",
    "                     'n_estimators': [100, 300, 900],\n",
    "                     'subsample': [0.1, 0.5, 1.0],\n",
    "                     'criterion': [\"friedman_mse\", \"mse\", \"mae\"],\n",
    "                     'min_samples_split': list(range(2, 51)),\n",
    "                     'min_samples_leaf': list(range(1, 51)),\n",
    "                     'max_depth': list(range(3, 51)),\n",
    "                     'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "                     'warm_start': [False, True], \n",
    "                     'n_iter_no_change': [10, 30, 90, None]}\n",
    "\n",
    "    #simple rule regressor\n",
    "    hp_dummy = {'strategy': [\"mean\", \"median\", \"quantile\"], \n",
    "            'quantile': [0.0, 0.25, 0.75, 1.0]}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"###### get_estimators_hyperparameters_to_search() ######\")\n",
    "        print(hp_lr)\n",
    "        print(hp_sgd)\n",
    "        print(hp_lasso)\n",
    "        print(hp_bayesian)\n",
    "        print(hp_knn)\n",
    "        print(hp_dt)\n",
    "        print(hp_svr)\n",
    "        print(hp_mlp)\n",
    "        print(hp_random_forest)\n",
    "        print(hp_ada_boost)\n",
    "        print(hp_gradient_boost)\n",
    "        print(hp_dummy, \"\\n\")\n",
    "        \n",
    "    return hp_lr, hp_sgd, hp_lasso, hp_bayesian, hp_knn, hp_dt, hp_svr, hp_mlp, hp_random_forest, hp_ada_boost, hp_gradient_boost, hp_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator, file_name : str, verbose=True):\n",
    "    dump(estimator, str(args.model_path + file_name + '.joblib')) \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"###### save_estimator() ######\")\n",
    "        print(\"estimator:\", estimator)\n",
    "        print(\"saved file:\", str(args.model_path + file_name + '.joblib'), \"\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_whole(estimator, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    tic = time.time()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    toc = time.time()    \n",
    "    if verbose: print(\"Training DONE\")\n",
    "    \n",
    "    y_pred = estimator.predict(X_test)\n",
    "    if verbose: print(\"Testing DONE\\n\\n\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"###### train_and_test_whole() ######\")\n",
    "        print(\"estimator:\", estimator)\n",
    "        print(\"X_train:\", X_train[:2])\n",
    "        print(\"y_train:\", y_train[:2])\n",
    "        print(\"X_test:\", X_test[:2])\n",
    "        print(\"y_test:\", y_test[:2], \"\\n\")\n",
    "        \n",
    "    return y_pred, (toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(performance_dict, data, subset, n, name, verbose=True): \n",
    "    df_results = pd.DataFrame.from_dict(performance_dict)\n",
    "    #i.e 'nasbench201_predictions_cifar10valid_200epochs_n172.csv'\n",
    "    # 'nasbench201_predictions_cifar100_200epochs_n172.csv'\n",
    "    # 'nasbench201_predictions_imagenet_16_120_200epochs_n172.csv'\n",
    "    df_results.to_csv(str(args.results_path + 'nasbench201_' + name + '_' \n",
    "                          + str(data) + '_' + str(subset) + 'epochs_n' \n",
    "                          + str(n) + '.csv'), index=False, float_format='%.6f')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"###### save_results() ######\")\n",
    "        print(\"saved file:\", str(args.results_path + 'nasbench201_' + name + '_' \n",
    "                                 + str(data) + '_' + str(subset) + 'epochs_n' + \n",
    "                                 str(n) + '.csv'), \"\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(verbose=True):\n",
    "    for data in args.dataset:        \n",
    "        \n",
    "        for subset in args.data_subset:\n",
    "        \n",
    "            #cifar10valid (4, 108, 200), cifar100 and imagenet16_120 (200)\n",
    "            if data in ('cifar100', 'imagenet16_120') and subset in (4, 108):\n",
    "                continue #above code is not executed\n",
    "                             \n",
    "            X, y = get_preprocessed_numpy_dataset(data, subset)\n",
    "\n",
    "            for n in args.train_size:\n",
    "                predictions = {'dataset': [], 'epoch': [], 'train_size': [], 'seed': [], 'model': [], \n",
    "                                   'id_arch': [], 'acc_valid_pred': [], 'acc_valid_true': [], 'acc_test_true': []}\n",
    "                fit_times = {'dataset': [], 'epoch': [], 'train_size': [], 'seed': [], 'model': [], 'fit_time': []}\n",
    "\n",
    "                for seed in args.seed:\n",
    "                    if verbose: \n",
    "                        print(\"\\n\\n\\n=========================================================\")\n",
    "                        print(\"=========== {}, Subset{}, N{}, Seed{} ===========\".format(data, subset, n, seed))\n",
    "                        print(\"=========================================================\")\n",
    "                    \n",
    "                    set_default_seed(seed)      \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n, random_state=seed, shuffle=True)                    \n",
    "                    if verbose:\n",
    "                        print(\"###### hold-out process ######\")\n",
    "                        print(\"len(X_train):\", len(X_train))\n",
    "                        print(\"len(X_test):\", len(X_test))\n",
    "                        print(\"len(y_train):\", len(y_train))\n",
    "                        print(\"len(y_test):\", len(y_test))\n",
    "\n",
    "                    min_max_scaler = MinMaxScaler()\n",
    "                    min_max_scaler.fit(X_train[:, 1:-1]) #ignore id_arch and acc_test columns\n",
    "                    X_train[:, 1:-1] = min_max_scaler.transform(X_train[:, 1:-1])\n",
    "                    X_test[:, 1:-1] = min_max_scaler.transform(X_test[:, 1:-1])                    \n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(\"\\n###### Normalization process ######\")\n",
    "                        print(\"X_train:\", X_train[:2])\n",
    "                        print(\"X_test:\", X_test[:2])\n",
    "\n",
    "                    estimators = get_estimators(seed)\n",
    "                    hyperparameters = get_estimators_hyperparameters_to_search()\n",
    "\n",
    "                    for reg, hp in zip(estimators, hyperparameters):\n",
    "                        rs = RandomizedSearchCV(estimator=reg, param_distributions=hp, n_iter=args.n_iter_rs, scoring=args.scoring_rs, \n",
    "                                                n_jobs=-1, cv=args.cv_inner, verbose=0, pre_dispatch='2*n_jobs', random_state=seed)\n",
    "\n",
    "                        reg_name = str(reg)[:str(reg).index('(')]\n",
    "                        if verbose: print(\"\\n#\", reg_name, \"#\")\n",
    "\n",
    "                        if verbose: print(\"\\n#########\", args.cv_inner, \"Fold RANDOM SEARCH #########\")\n",
    "                        #id_arch and acc_test columns are not included\n",
    "                        rs.fit(X_train[:, 1:-1], y_train) \n",
    "                        if verbose: print(\"DONE\")\n",
    "\n",
    "                        best_estimator = rs.best_estimator_\n",
    "                        if verbose: print(\"best estimator:\", best_estimator.get_params())\n",
    "\n",
    "                        if verbose: print(\"\\n######### HOLD-OUT VALIDATION #########\")\n",
    "                        y_pred, fit_time = train_and_test_whole(best_estimator, X_train[:, 1:-1], y_train, X_test[:, 1:-1], y_test)                       \n",
    "\n",
    "                        predictions['dataset'].extend([data] * len(y_pred))\n",
    "                        predictions['epoch'].extend([subset] * len(y_pred))\n",
    "                        predictions['train_size'].extend([n] * len(y_pred))\n",
    "                        predictions['seed'].extend([seed] * len(y_pred))\n",
    "                        predictions['model'].extend([reg_name] * len(y_pred))\n",
    "                        predictions['id_arch'].extend(X_test[:, 0]) #id_arch column                        \n",
    "                        predictions['acc_valid_pred'].extend(y_pred)\n",
    "                        predictions['acc_valid_true'].extend(y_test)\n",
    "                        predictions['acc_test_true'].extend(X_test[:, -1]) #acc_test column \n",
    "\n",
    "                        fit_times['dataset'].append(data)\n",
    "                        fit_times['epoch'].append(subset)\n",
    "                        fit_times['train_size'].append(n)\n",
    "                        fit_times['seed'].append(seed)\n",
    "                        fit_times['model'].append(reg_name)\n",
    "                        fit_times['fit_time'].append(fit_time)\n",
    "\n",
    "                        save_estimator(best_estimator, str('nasbench201_' + str(data) + '_' + str(subset) + 'epochs_n' \n",
    "                                                               + str(n) + '_seed' + str(seed) + '_' + reg_name))\n",
    "\n",
    "                #predictions and times for ALL models and ALL seeds, per each 1 dataset, 1 subset (epoch), and 1 n\n",
    "                save_results(predictions, data, subset, n, \"predictions\")\n",
    "                save_results(fit_times, data, subset, n, \"fit_times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path: /home/gean/nns_performance_prediction/meta_datasets/\n",
      "model_path: /home/gean/nns_performance_prediction/saved_models/\n",
      "results_path: /home/gean/nns_performance_prediction/results/fast/test12/\n",
      "target: acc_valid\n",
      "n_iter_rs: 2\n",
      "cv_inner: 3\n",
      "scoring_rs: r2\n",
      "dataset: ['imagenet16_120']\n",
      "data_subset: [4, 108, 200]\n",
      "seed: [0, 1, 10, 42, 100, 123, 666, 1000, 1234, 12345]\n",
      "train_size: [43, 86, 129, 172, 344, 860]\n",
      "estimators: ['linear_regression', 'sgd', 'lasso', 'bayesian_ridge', 'knn', 'dt', 'svm', 'mlp', 'random_forest', 'ada_boost', 'gradient_boost', 'dummy']\n",
      "features drop: ['str_arch', 'layers_all', 'adjacency_matrix', 'dataset', 'epoch', 'skip_connection_num_layers', 'zeroize_num_layers', 'flops', 'latency', 'time_train', 'time_valid', 'time_test', 'loss_train', 'loss_valid', 'loss_test', 'acc_train'] \n",
      "\n",
      "\n",
      "\n",
      "###### get_preprocessed_numpy_dataset() ######\n",
      "df_whole after pre-processing:     id_arch  conv_num_layers  conv_kernel_min  conv_kernel_max  \\\n",
      "17        0                2                1                1   \n",
      "35        1                3                3                3   \n",
      "53        2                2                3                3   \n",
      "71        3                0                0                0   \n",
      "89        4                2                1                1   \n",
      "\n",
      "    conv_kernel_mode  avg_pool_num_layers    params  acc_valid   acc_test  \n",
      "17                 1                    1  0.136456  28.211111  26.633333  \n",
      "35                 3                    1  0.809576  44.488889  44.033333  \n",
      "53                 3                    4  0.566536  27.633333  27.255556  \n",
      "71                 0                    1  0.080456  29.433333  28.044444  \n",
      "89                 1                    0  0.136456  32.144444  31.488889  \n",
      "df_X:     id_arch  conv_num_layers  conv_kernel_min  conv_kernel_max  \\\n",
      "17        0                2                1                1   \n",
      "35        1                3                3                3   \n",
      "\n",
      "    conv_kernel_mode  avg_pool_num_layers    params   acc_test  \n",
      "17                 1                    1  0.136456  26.633333  \n",
      "35                 3                    1  0.809576  44.033333  \n",
      "df_y: 17    28.211111\n",
      "35    44.488889\n",
      "Name: acc_valid, dtype: float64\n",
      "X numpy: [[ 0.          2.          1.          1.          1.          1.\n",
      "   0.136456   26.63333329]\n",
      " [ 1.          3.          3.          3.          3.          1.\n",
      "   0.809576   44.03333325]]\n",
      "X numpy shape: (15625, 8)\n",
      "y numpy: [28.21111108 44.48888876]\n",
      "y numpy shape: (15625,) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed0 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[7.97000000e+02 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.63616558e-01 4.27333332e+01]\n",
      " [7.55000000e+02 3.33333333e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 4.72766885e-01 3.50333333e+01]]\n",
      "X_test: [[4.41400000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 2.63616558e-01 1.68666667e+01]\n",
      " [1.41830000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 5.27233115e-01 3.46333333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=0,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=0), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=0, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(685,), (560, 630), (193, 836, 764)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.54488318, 0.4236548 , 0.64589411, 0.43758721, 0.891773  ,\n",
      "       0.96366276, 0.38344152, 0.79172504, 0.52889492, 0.56804456,\n",
      "       0.92559664, 0.07103606, 0.0871293 , 0.0202184 , 0.83261985,\n",
      "       0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
      "       0.78052918, 0.11827443, 0.63992102, 0.14335329, 0.94466892,\n",
      "       0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
      "       0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
      "       0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
      "       0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
      "       0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 1000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 0, 'selection': 'random', 'tol': 1e-05, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=0,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=0,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 15, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=15, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=15, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 24, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (193, 836, 764), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6667667154456677, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 46, 'min_samples_split': 20, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=46,\n",
      "                      min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=46,\n",
      "                      min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 36, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 29, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.1, loss='quantile', max_depth=36,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=29, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=0, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.1, loss='quantile', max_depth=36,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=29, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=0, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.33333333 1.         1.         1.         1.         0.47276688]]\n",
      "y_train: [42.17777767 35.39999997]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed0_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed1 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[3.60600000e+03 2.50000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.50000000e-01 2.33222222e+01]\n",
      " [2.87700000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.78801843e-01 4.02888888e+01]]\n",
      "X_test: [[1.43700000e+04 2.50000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.50000000e-01 3.95777777e+01]\n",
      " [1.40900000e+03 5.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 5.76036866e-02 2.82555555e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(38,), (236, 73), (768, 716, 646)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.14675589, 0.09233859, 0.18626021, 0.34556073, 0.39676747,\n",
      "       0.53881673, 0.41919451, 0.6852195 , 0.20445225, 0.87811744,\n",
      "       0.02738759, 0.67046751, 0.4173048 , 0.55868983, 0.14038694,\n",
      "       0.19810149, 0.80074457, 0.96826158, 0.31342418, 0.69232262,\n",
      "       0.87638915, 0.89460666, 0.08504421, 0.03905478, 0.16983042,\n",
      "       0.8781425 , 0.09834683, 0.42110763, 0.95788953, 0.53316528,\n",
      "       0.69187711, 0.31551563, 0.68650093, 0.83462567, 0.01828828,\n",
      "       0.75014431, 0.98886109, 0.74816565, 0.28044399, 0.78927933,\n",
      "       0.10322601, 0.44789353, 0.9085955 , 0.29361415, 0.28777534,\n",
      "       0.13002857, 0.01936696, 0.67883553, 0.21162812, 0.26554666]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 18, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=18, min_samples_split=46,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=18, min_samples_split=46,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.4191945144032948, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 18, 'min_samples_split': 38, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=18,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=18,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 14, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 32, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=14,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=32, min_samples_split=33,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=14,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=32, min_samples_split=33,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "X_train: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.27880184]]\n",
      "y_train: [24.59999995 39.6555554 ]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.25      ]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed10 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.50060000e+04 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 6.42011834e-01 2.39000000e+01]\n",
      " [1.20620000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 3.21005917e-01 3.98999999e+01]]\n",
      "X_test: [[8.96300000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 9.63017751e-01 1.77333333e+01]\n",
      " [4.03800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 7.39644970e-02 3.54555556e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=10,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=10,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=10), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(266,), (126, 528), (321, 370, 124)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.83191136, 0.58332174, 0.02517173, 0.70920801, 0.26556613,\n",
      "       0.26360285, 0.15037787, 0.68381843, 0.81660184, 0.33607158,\n",
      "       0.89081653, 0.19812181, 0.03061665, 0.87761494, 0.72743551,\n",
      "       0.54088093, 0.13145815, 0.41366737, 0.77872881, 0.58390137,\n",
      "       0.18263144, 0.82608225, 0.10540183, 0.28357668, 0.06556327,\n",
      "       0.05644419, 0.76545582, 0.01178803, 0.61194334, 0.33188226,\n",
      "       0.55964837, 0.33549965, 0.41118255, 0.0768555 , 0.85304299,\n",
      "       0.43998746, 0.12195415, 0.73173462, 0.13878247, 0.76688005,\n",
      "       0.83198977, 0.30977806, 0.59758229, 0.87239246, 0.98302087,\n",
      "       0.46740328, 0.87574449, 0.2960687 , 0.13129105, 0.84281793]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 10, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 10, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 13, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=13, p=1,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=13, p=1,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 10, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 22, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (321, 370, 124), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 3000, 'momentum': 0.06556326635477827, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 42, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 10, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=42,\n",
      "                      min_samples_split=27, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=42,\n",
      "                      min_samples_split=27, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 150, 'random_state': 10}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=150, random_state=10)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=150, random_state=10)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 14, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 29, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 10, 'presort': 'deprecated', 'random_state': 10, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.64201183]\n",
      " [0.2        1.         1.         1.         0.         0.32100592]]\n",
      "y_train: [23.66666662 39.98333337]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.96301775]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.0739645 ]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed10_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed42 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.89000000e+02 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 4.00000000e-01 4.35444445e+01]\n",
      " [9.99800000e+03 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 4.00000000e-01 2.00000000e-01 3.61444444e+01]]\n",
      "X_test: [[1.35140000e+04 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 4.46082949e-01 3.56999999e+01]\n",
      " [6.70500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 6.00000000e-01 2.23041475e-01 2.88666666e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=42,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(103,), (436, 861), (271, 107, 72)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.59865848, 0.15601864, 0.15599452, 0.05808361, 0.86617615,\n",
      "       0.60111501, 0.70807258, 0.02058449, 0.96990985, 0.83244264,\n",
      "       0.21233911, 0.18182497, 0.18340451, 0.30424224, 0.52475643,\n",
      "       0.43194502, 0.29122914, 0.61185289, 0.13949386, 0.29214465,\n",
      "       0.36636184, 0.45606998, 0.78517596, 0.19967378, 0.51423444,\n",
      "       0.59241457, 0.04645041, 0.60754485, 0.17052412, 0.06505159,\n",
      "       0.94888554, 0.96563203, 0.80839735, 0.30461377, 0.09767211,\n",
      "       0.68423303, 0.44015249, 0.12203823, 0.49517691, 0.03438852,\n",
      "       0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802,\n",
      "       0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'huber', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='huber', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='huber', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'random', 'tol': 0.001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 36, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (103,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.9695846277645586, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 22, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': True, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 150, 'random_state': 42}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 15, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.4 1.  1.  1.  0.2 0.4]\n",
      " [0.2 1.  1.  1.  0.4 0.2]]\n",
      "y_train: [43.65555548 37.01111107]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed42_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed100 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[4.23100000e+03 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 7.50000000e-01 2.43001120e-01 2.28999999e+01]\n",
      " [2.88300000e+03 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 7.50000000e-01 2.43001120e-01 3.22444444e+01]]\n",
      "X_test: [[3.28900000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.70996641e-01 3.97444443e+01]\n",
      " [4.82500000e+03 1.00000000e+00 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.69988802e-01 4.32499999e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=100, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=100), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=100, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(521,), (793, 836), (872, 856, 80)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.84477613, 0.00471886, 0.12156912, 0.67074908, 0.82585276,\n",
      "       0.13670659, 0.57509333, 0.89132195, 0.20920212, 0.18532822,\n",
      "       0.10837689, 0.21969749, 0.97862378, 0.81168315, 0.17194101,\n",
      "       0.81622475, 0.27407375, 0.43170418, 0.94002982, 0.81764938,\n",
      "       0.33611195, 0.17541045, 0.37283205, 0.00568851, 0.25242635,\n",
      "       0.79566251, 0.01525497, 0.59884338, 0.60380454, 0.10514769,\n",
      "       0.38194344, 0.03647606, 0.89041156, 0.98092086, 0.05994199,\n",
      "       0.89054594, 0.5769015 , 0.74247969, 0.63018394, 0.58184219,\n",
      "       0.02043913, 0.21002658, 0.54468488, 0.76911517, 0.25069523,\n",
      "       0.28589569, 0.85239509, 0.97500649, 0.88485329, 0.35950784]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 100, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 100, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 20, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 100, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (793, 836), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.8905459447285041, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 100, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 16, 'min_samples_split': 17, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 100, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 100}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=100)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=100)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 48, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 100, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.2        1.         1.         1.         0.75       0.24300112]\n",
      " [0.2        1.         1.         1.         0.75       0.24300112]]\n",
      "y_train: [22.60000002 31.4111111 ]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed100_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed123 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.15900000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 4.86002240e-01 3.25222222e+01]\n",
      " [7.34400000e+03 1.00000000e+00 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 1.39977604e-01 3.58333333e+01]]\n",
      "X_test: [[2.43000000e+03 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 2.43001120e-01 2.75444444e+01]\n",
      " [1.49400000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 5.13997760e-01 3.80777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=123,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=123,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=123, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=123), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=123, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(511,), (366, 383), (323, 99, 743)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.71915031, 0.49111893, 0.78002776, 0.41092437, 0.5796943 ,\n",
      "       0.13995076, 0.40101756, 0.62731701, 0.32415089, 0.24475928,\n",
      "       0.69475518, 0.5939024 , 0.63179202, 0.44025718, 0.08372648,\n",
      "       0.71233018, 0.42786349, 0.2977805 , 0.49208478, 0.74029639,\n",
      "       0.35772892, 0.41720995, 0.65472131, 0.37380143, 0.23451288,\n",
      "       0.98799529, 0.76599595, 0.77700444, 0.02798196, 0.17390652,\n",
      "       0.15408224, 0.07708648, 0.8898657 , 0.7503787 , 0.69340324,\n",
      "       0.51176338, 0.46426806, 0.56843069, 0.30254945, 0.49730879,\n",
      "       0.68326291, 0.91669867, 0.10892895, 0.49549179, 0.23283593,\n",
      "       0.43686066, 0.75154299, 0.48089213, 0.79772841, 0.28270293]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 123, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 47, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (366, 383), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.4920847767923423, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 48, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': True, 'random_state': 123, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=48,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=True,\n",
      "                      random_state=123, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=48,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=True,\n",
      "                      random_state=123, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'square', 'n_estimators': 450, 'random_state': 123}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 46, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 123, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.4        1.         1.         1.         0.66666667 0.48600224]\n",
      " [1.         0.33333333 0.33333333 0.33333333 0.         0.1399776 ]]\n",
      "y_train: [32.7333333  36.10000004]\n",
      "X_test: [[0.2        1.         1.         1.         0.66666667 0.24300112]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.51399776]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed123_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed666 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.36130000e+04 5.00000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e-01 3.71735791e-01 3.30333333e+01]\n",
      " [5.54000000e+02 2.50000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 2.50000000e-01 3.33333333e-01 4.01333332e+01]]\n",
      "X_test: [[7.37700000e+03 2.50000000e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50000000e-01 3.84024578e-02 2.87000000e+01]\n",
      " [6.01100000e+03 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.94930876e-01 3.92777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=666,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=666,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=666, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=666), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(237,), (899, 430), (831, 71, 415)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.95145796, 0.0127032 , 0.4135877 , 0.04881279, 0.09992856,\n",
      "       0.50806631, 0.20024754, 0.74415417, 0.192892  , 0.70084475,\n",
      "       0.29322811, 0.77447945, 0.00510884, 0.11285765, 0.11095367,\n",
      "       0.24766823, 0.0232363 , 0.72732115, 0.34003494, 0.19750316,\n",
      "       0.90917959, 0.97834699, 0.53280254, 0.25913185, 0.58381262,\n",
      "       0.32569065, 0.88889931, 0.62640453, 0.81887369, 0.54734542,\n",
      "       0.41671201, 0.74304719, 0.36959638, 0.07516654, 0.77519298,\n",
      "       0.21940924, 0.07934213, 0.48678052, 0.1536739 , 0.82846513,\n",
      "       0.19136857, 0.27040895, 0.56103442, 0.90238039, 0.85178834,\n",
      "       0.41808196, 0.39347627, 0.01622051, 0.29921337, 0.35377822]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 666, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 666, 'selection': 'random', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 8, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 22, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 48, 'min_samples_split': 35, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 666, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 35, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (831, 71, 415), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.0751665439471918, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 666, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 19, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 666, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 666}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 45, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 666, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=45,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=12, min_samples_split=3,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=45,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=12, min_samples_split=3,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "X_train: [[0.5        0.         1.         0.         0.5        0.37173579]\n",
      " [0.25       0.         1.         0.         0.25       0.33333333]]\n",
      "y_train: [32.96666666 39.90000002]\n",
      "X_test: [[0.25       0.         0.         0.         0.25       0.03840246]\n",
      " [0.         1.         1.         1.         0.25       0.29493088]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed666_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed1000 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.10000000e+01 6.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 5.00000000e-01 9.61597542e-01 3.01666666e+01]\n",
      " [1.18450000e+04 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 7.50000000e-01 2.94930876e-01 2.56000000e+01]]\n",
      "X_test: [[8.32500000e+03 3.33333333e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.33333333e-01 3.49222221e+01]\n",
      " [1.41650000e+04 6.66666667e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e-01 3.71735791e-01 3.65888888e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1000,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1000, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1000, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1000), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(436,), (600, 72), (705, 252, 351)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.4821914 , 0.87247454, 0.21233268, 0.04070962, 0.39719446,\n",
      "       0.2331322 , 0.84174072, 0.20708234, 0.74246953, 0.39215413,\n",
      "       0.18225652, 0.74353941, 0.06958208, 0.8853372 , 0.9526444 ,\n",
      "       0.93114343, 0.41543095, 0.02898166, 0.98202748, 0.33963768,\n",
      "       0.70668719, 0.36187707, 0.0351059 , 0.85505825, 0.65725351,\n",
      "       0.76568299, 0.55408724, 0.88509294, 0.90419762, 0.0104217 ,\n",
      "       0.07455674, 0.24462921, 0.13330475, 0.6979251 , 0.39820488,\n",
      "       0.88312219, 0.18100751, 0.43249917, 0.0181432 , 0.69143786,\n",
      "       0.46969065, 0.12822219, 0.89133705, 0.91820362, 0.07312099,\n",
      "       0.04544794, 0.4385729 , 0.60172093, 0.31022703, 0.68190824]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 1000, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1000, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=18, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=18, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 30, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1000, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 25, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (600, 72), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 9000, 'momentum': 0.855058253240408, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1000, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=9000,\n",
      "             momentum=0.855058253240408, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=9000,\n",
      "             momentum=0.855058253240408, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 1000, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50, 'random_state': 1000}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.1, 'loss': 'lad', 'max_depth': 49, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 30, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1000, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.66666667 1.         1.         1.         0.5        0.96159754]\n",
      " [0.         1.         1.         1.         0.75       0.29493088]]\n",
      "y_train: [30.41111109 26.61111111]\n",
      "X_test: [[0.33333333 0.         1.         0.         0.         0.33333333]\n",
      " [0.66666667 0.         1.         0.         0.5        0.37173579]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1000_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed1234 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.21070000e+04 5.00000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 5.00000000e-01 4.06333334e+01]\n",
      " [4.84100000e+03 5.00000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e-01 2.78801843e-01 3.91499999e+01]]\n",
      "X_test: [[5.76300000e+03 2.50000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 4.71198157e-01 2.80000000e+01]\n",
      " [2.81500000e+03 5.00000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 2.50000000e-01 2.78801843e-01 3.98222222e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1234,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1234,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1234), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(816,), (724, 295), (54, 205, 373)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.78535858, 0.77997581, 0.27259261, 0.27646426, 0.80187218,\n",
      "       0.95813935, 0.87593263, 0.35781727, 0.50099513, 0.68346294,\n",
      "       0.71270203, 0.37025075, 0.56119619, 0.50308317, 0.01376845,\n",
      "       0.77282662, 0.88264119, 0.36488598, 0.61539618, 0.07538124,\n",
      "       0.36882401, 0.9331401 , 0.65137814, 0.39720258, 0.78873014,\n",
      "       0.31683612, 0.56809865, 0.86912739, 0.43617342, 0.80214764,\n",
      "       0.14376682, 0.70426097, 0.70458131, 0.21879211, 0.92486763,\n",
      "       0.44214076, 0.90931596, 0.05980922, 0.18428708, 0.04735528,\n",
      "       0.67488094, 0.59462478, 0.53331016, 0.04332406, 0.56143308,\n",
      "       0.32966845, 0.50296683, 0.11189432, 0.60719371, 0.56594464]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1234, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': False, 'positive': True, 'precompute': False, 'random_state': 1234, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1234, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (54, 205, 373), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 9000, 'momentum': 0.04735527880151513, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1234, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(54, 205, 373), learning_rate='invscaling',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.04735527880151513, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(54, 205, 373), learning_rate='invscaling',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.04735527880151513, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1234, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1234}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 34, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1234, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "X_train: [[0.5        0.         1.         1.         0.25       0.5       ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_train: [40.44999998 38.56666667]\n",
      "X_test: [[0.25       1.         1.         1.         0.25       0.47119816]\n",
      " [0.5        0.         1.         0.         0.25       0.27880184]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed1234_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N43, Seed12345 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 43\n",
      "len(X_test): 15582\n",
      "len(y_train): 43\n",
      "len(y_test): 15582\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.22710000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 5.15929624e-01 3.67444444e+01]\n",
      " [2.62400000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 3.45221113e-01 3.94111111e+01]]\n",
      "X_test: [[9.59200000e+03 2.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.56633381e-02 1.53333333e+01]\n",
      " [8.81300000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.54778887e-01 3.92833333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=12345,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=12345,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=12345, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=12345), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(483,), (486, 286), (130, 421, 426)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.20456028, 0.56772503, 0.5955447 , 0.96451452, 0.6531771 ,\n",
      "       0.74890664, 0.65356987, 0.74771481, 0.96130674, 0.0083883 ,\n",
      "       0.10644438, 0.29870371, 0.65641118, 0.80981255, 0.87217591,\n",
      "       0.9646476 , 0.72368535, 0.64247533, 0.71745362, 0.46759901,\n",
      "       0.32558468, 0.43964461, 0.72968908, 0.99401459, 0.67687371,\n",
      "       0.79082252, 0.17091426, 0.02684928, 0.80037024, 0.90372254,\n",
      "       0.02467621, 0.49174732, 0.52625517, 0.59636601, 0.05195755,\n",
      "       0.89508953, 0.72826618, 0.81835001, 0.50022275, 0.81018941,\n",
      "       0.09596853, 0.21895004, 0.25871906, 0.46810575, 0.4593732 ,\n",
      "       0.70950978, 0.17805301, 0.53144988, 0.16774223, 0.76881392]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'squared_loss', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 12345, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 12345, 'selection': 'random', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 49, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 39, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 12345, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 21, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (130, 421, 426), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 9000, 'momentum': 0.5677250290816866, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 12345, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(130, 421, 426), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.5677250290816866, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(130, 421, 426), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.5677250290816866, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 22, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 12345}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 20, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 31, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 12345, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.2        1.         1.         1.         0.66666667 0.51592962]\n",
      " [0.4        0.33333333 1.         0.33333333 0.33333333 0.34522111]]\n",
      "y_train: [36.46666664 38.5444444 ]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n43_seed12345_DummyRegressor.joblib \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_predictions_imagenet16_120_200epochs_n43.csv \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_fit_times_imagenet16_120_200epochs_n43.csv \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed0 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.21340000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 3.18082789e-01 3.54999999e+01]\n",
      " [1.46270000e+04 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 2.36383442e-01 3.89000000e+01]]\n",
      "X_test: [[4.41400000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 2.63616558e-01 1.68666667e+01]\n",
      " [1.41830000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 5.27233115e-01 3.46333333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=0,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=0), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=0, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(685,), (560, 630), (193, 836, 764)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.54488318, 0.4236548 , 0.64589411, 0.43758721, 0.891773  ,\n",
      "       0.96366276, 0.38344152, 0.79172504, 0.52889492, 0.56804456,\n",
      "       0.92559664, 0.07103606, 0.0871293 , 0.0202184 , 0.83261985,\n",
      "       0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
      "       0.78052918, 0.11827443, 0.63992102, 0.14335329, 0.94466892,\n",
      "       0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
      "       0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
      "       0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
      "       0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
      "       0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 29, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=29, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=29, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (193, 836, 764), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6667667154456677, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.31808279]\n",
      " [0.16666667 1.         1.         1.         0.33333333 0.23638344]]\n",
      "y_train: [35.26666658 38.49999987]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.33333333 0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed0_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed1 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.40890000e+04 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.78801843e-01 3.18333333e+01]\n",
      " [1.04600000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 5.28801843e-01 4.25222221e+01]]\n",
      "X_test: [[1.43700000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.50000000e-01 3.95777777e+01]\n",
      " [1.40900000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 5.76036866e-02 2.82555555e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(38,), (236, 73), (768, 716, 646)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.14675589, 0.09233859, 0.18626021, 0.34556073, 0.39676747,\n",
      "       0.53881673, 0.41919451, 0.6852195 , 0.20445225, 0.87811744,\n",
      "       0.02738759, 0.67046751, 0.4173048 , 0.55868983, 0.14038694,\n",
      "       0.19810149, 0.80074457, 0.96826158, 0.31342418, 0.69232262,\n",
      "       0.87638915, 0.89460666, 0.08504421, 0.03905478, 0.16983042,\n",
      "       0.8781425 , 0.09834683, 0.42110763, 0.95788953, 0.53316528,\n",
      "       0.69187711, 0.31551563, 0.68650093, 0.83462567, 0.01828828,\n",
      "       0.75014431, 0.98886109, 0.74816565, 0.28044399, 0.78927933,\n",
      "       0.10322601, 0.44789353, 0.9085955 , 0.29361415, 0.28777534,\n",
      "       0.13002857, 0.01936696, 0.67883553, 0.21162812, 0.26554666]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 1, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=1, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=1, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.4191945144032948, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 18, 'min_samples_split': 38, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=18,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=18,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 14, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 32, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=14,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=32, min_samples_split=33,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=14,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=32, min_samples_split=33,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.         0.27880184]\n",
      " [0.6        0.33333333 1.         1.         0.25       0.52880184]]\n",
      "y_train: [32.05555549 42.15555555]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.25      ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05760369]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed10 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[9.58000000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 6.54778887e-01 4.23333332e+01]\n",
      " [1.00340000e+04 6.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 1.06990014e-01 3.81833333e+01]]\n",
      "X_test: [[8.96300000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 9.28673324e-01 1.77333333e+01]\n",
      " [4.03800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 7.13266762e-02 3.54555556e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=10,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=10,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=10), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(266,), (126, 528), (321, 370, 124)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.83191136, 0.58332174, 0.02517173, 0.70920801, 0.26556613,\n",
      "       0.26360285, 0.15037787, 0.68381843, 0.81660184, 0.33607158,\n",
      "       0.89081653, 0.19812181, 0.03061665, 0.87761494, 0.72743551,\n",
      "       0.54088093, 0.13145815, 0.41366737, 0.77872881, 0.58390137,\n",
      "       0.18263144, 0.82608225, 0.10540183, 0.28357668, 0.06556327,\n",
      "       0.05644419, 0.76545582, 0.01178803, 0.61194334, 0.33188226,\n",
      "       0.55964837, 0.33549965, 0.41118255, 0.0768555 , 0.85304299,\n",
      "       0.43998746, 0.12195415, 0.73173462, 0.13878247, 0.76688005,\n",
      "       0.83198977, 0.30977806, 0.59758229, 0.87239246, 0.98302087,\n",
      "       0.46740328, 0.87574449, 0.2960687 , 0.13129105, 0.84281793]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 10, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 10, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 10, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 48, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=48, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=48, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (321, 370, 124), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 3000, 'momentum': 0.06556326635477827, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 10, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 150, 'random_state': 10}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=150, random_state=10)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=150, random_state=10)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 32, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 6, 'min_samples_split': 32, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 10, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='quantile',\n",
      "                          max_depth=32, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=6,\n",
      "                          min_samples_split=32, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='quantile',\n",
      "                          max_depth=32, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=6,\n",
      "                          min_samples_split=32, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.6        0.33333333 1.         1.         0.         0.65477889]\n",
      " [0.6        0.33333333 0.33333333 0.33333333 0.33333333 0.10699001]]\n",
      "y_train: [42.81666656 36.91666665]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed10_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed42 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[3.07300000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 4.00000000e-01 4.60829493e-02 3.23833333e+01]\n",
      " [7.55500000e+03 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 6.23041475e-01 3.94111110e+01]]\n",
      "X_test: [[1.35140000e+04 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 4.46082949e-01 3.56999999e+01]\n",
      " [6.70500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 6.00000000e-01 2.23041475e-01 2.88666666e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=42,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(103,), (436, 861), (271, 107, 72)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.59865848, 0.15601864, 0.15599452, 0.05808361, 0.86617615,\n",
      "       0.60111501, 0.70807258, 0.02058449, 0.96990985, 0.83244264,\n",
      "       0.21233911, 0.18182497, 0.18340451, 0.30424224, 0.52475643,\n",
      "       0.43194502, 0.29122914, 0.61185289, 0.13949386, 0.29214465,\n",
      "       0.36636184, 0.45606998, 0.78517596, 0.19967378, 0.51423444,\n",
      "       0.59241457, 0.04645041, 0.60754485, 0.17052412, 0.06505159,\n",
      "       0.94888554, 0.96563203, 0.80839735, 0.30461377, 0.09767211,\n",
      "       0.68423303, 0.44015249, 0.12203823, 0.49517691, 0.03438852,\n",
      "       0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802,\n",
      "       0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'huber', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='huber', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='huber', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'random', 'tol': 0.001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 36, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (103,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.2587799816000169, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.2587799816000169, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.2587799816000169, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 22, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': True, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 42}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=450, random_state=42)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=450, random_state=42)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 15, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.4        0.04608295]\n",
      " [0.8        0.33333333 1.         1.         0.2        0.62304147]]\n",
      "y_train: [33.31666666 39.18888885]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed42_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed100 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.48110000e+04 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 2.63616558e-01 4.26333332e+01]\n",
      " [3.41900000e+03 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 7.36383442e-01 4.42333332e+01]]\n",
      "X_test: [[3.28900000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.63616558e-01 3.97444443e+01]\n",
      " [4.82500000e+03 8.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.54466231e-01 4.32499999e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=100, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=100), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=100, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(521,), (793, 836), (872, 856, 80)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.84477613, 0.00471886, 0.12156912, 0.67074908, 0.82585276,\n",
      "       0.13670659, 0.57509333, 0.89132195, 0.20920212, 0.18532822,\n",
      "       0.10837689, 0.21969749, 0.97862378, 0.81168315, 0.17194101,\n",
      "       0.81622475, 0.27407375, 0.43170418, 0.94002982, 0.81764938,\n",
      "       0.33611195, 0.17541045, 0.37283205, 0.00568851, 0.25242635,\n",
      "       0.79566251, 0.01525497, 0.59884338, 0.60380454, 0.10514769,\n",
      "       0.38194344, 0.03647606, 0.89041156, 0.98092086, 0.05994199,\n",
      "       0.89054594, 0.5769015 , 0.74247969, 0.63018394, 0.58184219,\n",
      "       0.02043913, 0.21002658, 0.54468488, 0.76911517, 0.25069523,\n",
      "       0.28589569, 0.85239509, 0.97500649, 0.88485329, 0.35950784]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 100, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 1000, 'normalize': False, 'positive': False, 'precompute': False, 'random_state': 100, 'selection': 'random', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='random', tol=0.0001, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='random', tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 24, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 100, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (793, 836), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.8905459447285041, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 100, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 16, 'min_samples_split': 17, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 100, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 50, 'random_state': 100}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 48, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 100, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.33333333 0.33333333 1.         0.33333333 0.5        0.26361656]\n",
      " [0.66666667 0.33333333 1.         1.         0.         0.73638344]]\n",
      "y_train: [43.16666666 43.73333329]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed100_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed123 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[4.45500000e+03 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 3.33333333e-01 5.27233115e-01 4.33166666e+01]\n",
      " [3.31600000e+03 5.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 8.16993464e-02 3.94833333e+01]]\n",
      "X_test: [[2.43000000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 2.36383442e-01 2.75444444e+01]\n",
      " [1.49400000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 5.00000000e-01 3.80777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=123,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=123,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=123, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=123), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=123, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(511,), (366, 383), (323, 99, 743)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.71915031, 0.49111893, 0.78002776, 0.41092437, 0.5796943 ,\n",
      "       0.13995076, 0.40101756, 0.62731701, 0.32415089, 0.24475928,\n",
      "       0.69475518, 0.5939024 , 0.63179202, 0.44025718, 0.08372648,\n",
      "       0.71233018, 0.42786349, 0.2977805 , 0.49208478, 0.74029639,\n",
      "       0.35772892, 0.41720995, 0.65472131, 0.37380143, 0.23451288,\n",
      "       0.98799529, 0.76599595, 0.77700444, 0.02798196, 0.17390652,\n",
      "       0.15408224, 0.07708648, 0.8898657 , 0.7503787 , 0.69340324,\n",
      "       0.51176338, 0.46426806, 0.56843069, 0.30254945, 0.49730879,\n",
      "       0.68326291, 0.91669867, 0.10892895, 0.49549179, 0.23283593,\n",
      "       0.43686066, 0.75154299, 0.48089213, 0.79772841, 0.28270293]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 123, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 47, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (323, 99, 743), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 1000, 'momentum': 0.4973087863238618, 'n_iter_no_change': 90, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(323, 99, 743), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=1000,\n",
      "             momentum=0.4973087863238618, n_iter_no_change=90,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(323, 99, 743), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=1000,\n",
      "             momentum=0.4973087863238618, n_iter_no_change=90,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 38, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 123}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 46, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 123, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.33333333 0.52723312]\n",
      " [0.5        0.33333333 0.33333333 0.33333333 0.33333333 0.08169935]]\n",
      "y_train: [42.99999988 39.11666656]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.66666667 0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed123_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed666 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[8.87900000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 3.57988166e-01 1.60666666e+01]\n",
      " [9.89600000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 3.57988166e-01 3.33666666e+01]]\n",
      "X_test: [[7.37700000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 7.39644970e-02 2.87000000e+01]\n",
      " [6.01100000e+03 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 3.21005917e-01 3.92777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=666,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=666,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=666, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=666), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(237,), (899, 430), (831, 71, 415)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.95145796, 0.0127032 , 0.4135877 , 0.04881279, 0.09992856,\n",
      "       0.50806631, 0.20024754, 0.74415417, 0.192892  , 0.70084475,\n",
      "       0.29322811, 0.77447945, 0.00510884, 0.11285765, 0.11095367,\n",
      "       0.24766823, 0.0232363 , 0.72732115, 0.34003494, 0.19750316,\n",
      "       0.90917959, 0.97834699, 0.53280254, 0.25913185, 0.58381262,\n",
      "       0.32569065, 0.88889931, 0.62640453, 0.81887369, 0.54734542,\n",
      "       0.41671201, 0.74304719, 0.36959638, 0.07516654, 0.77519298,\n",
      "       0.21940924, 0.07934213, 0.48678052, 0.1536739 , 0.82846513,\n",
      "       0.19136857, 0.27040895, 0.56103442, 0.90238039, 0.85178834,\n",
      "       0.41808196, 0.39347627, 0.01622051, 0.29921337, 0.35377822]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 666, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 666, 'selection': 'random', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 8, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 22, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 48, 'min_samples_split': 35, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 666, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 35, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (831, 71, 415), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.0751665439471918, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 666, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 19, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 666, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 666}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.01, 'loss': 'lad', 'max_depth': 19, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 666, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.25       0.35798817]\n",
      " [0.4        0.33333333 1.         0.33333333 0.         0.35798817]]\n",
      "y_train: [17.00000001 34.28333331]\n",
      "X_test: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.0739645 ]\n",
      " [0.2        1.         1.         1.         0.25       0.32100592]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed666_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed1000 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.0886e+04 2.5000e-01 0.0000e+00 1.0000e+00 0.0000e+00 2.5000e-01\n",
      "  2.5000e-01 4.2100e+01]\n",
      " [1.0793e+04 7.5000e-01 0.0000e+00 1.0000e+00 1.0000e+00 2.5000e-01\n",
      "  7.5000e-01 4.5150e+01]]\n",
      "X_test: [[8.32500000e+03 2.50000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.50000000e-01 3.49222221e+01]\n",
      " [1.41650000e+04 5.00000000e-01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e-01 2.78801843e-01 3.65888888e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1000,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1000, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1000, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1000), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(436,), (600, 72), (705, 252, 351)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.4821914 , 0.87247454, 0.21233268, 0.04070962, 0.39719446,\n",
      "       0.2331322 , 0.84174072, 0.20708234, 0.74246953, 0.39215413,\n",
      "       0.18225652, 0.74353941, 0.06958208, 0.8853372 , 0.9526444 ,\n",
      "       0.93114343, 0.41543095, 0.02898166, 0.98202748, 0.33963768,\n",
      "       0.70668719, 0.36187707, 0.0351059 , 0.85505825, 0.65725351,\n",
      "       0.76568299, 0.55408724, 0.88509294, 0.90419762, 0.0104217 ,\n",
      "       0.07455674, 0.24462921, 0.13330475, 0.6979251 , 0.39820488,\n",
      "       0.88312219, 0.18100751, 0.43249917, 0.0181432 , 0.69143786,\n",
      "       0.46969065, 0.12822219, 0.89133705, 0.91820362, 0.07312099,\n",
      "       0.04544794, 0.4385729 , 0.60172093, 0.31022703, 0.68190824]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 1000, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1000, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 25, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=25, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=25, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 30, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1000, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 25, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (600, 72), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.7656829941452387, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1000, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 1000, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50, 'random_state': 1000}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 39, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1000, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='huber', max_depth=39,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=50,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='huber', max_depth=39,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=50,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.25 0.   1.   0.   0.25 0.25]\n",
      " [0.75 0.   1.   1.   0.25 0.75]]\n",
      "y_train: [40.23333333 45.26666666]\n",
      "X_test: [[0.25       0.         1.         0.         0.         0.25      ]\n",
      " [0.5        0.         1.         0.         0.5        0.27880184]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1000_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed1234 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[8.10800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 5.59910414e-02 3.37333333e+01]\n",
      " [5.20600000e+03 1.00000000e+00 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.69988802e-01 4.15333333e+01]]\n",
      "X_test: [[5.76300000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 4.86002240e-01 2.80000000e+01]\n",
      " [2.81500000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.98992161e-01 3.98222222e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1234,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1234,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1234), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(816,), (724, 295), (54, 205, 373)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.78535858, 0.77997581, 0.27259261, 0.27646426, 0.80187218,\n",
      "       0.95813935, 0.87593263, 0.35781727, 0.50099513, 0.68346294,\n",
      "       0.71270203, 0.37025075, 0.56119619, 0.50308317, 0.01376845,\n",
      "       0.77282662, 0.88264119, 0.36488598, 0.61539618, 0.07538124,\n",
      "       0.36882401, 0.9331401 , 0.65137814, 0.39720258, 0.78873014,\n",
      "       0.31683612, 0.56809865, 0.86912739, 0.43617342, 0.80214764,\n",
      "       0.14376682, 0.70426097, 0.70458131, 0.21879211, 0.92486763,\n",
      "       0.44214076, 0.90931596, 0.05980922, 0.18428708, 0.04735528,\n",
      "       0.67488094, 0.59462478, 0.53331016, 0.04332406, 0.56143308,\n",
      "       0.32966845, 0.50296683, 0.11189432, 0.60719371, 0.56594464]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1234, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': False, 'positive': True, 'precompute': False, 'random_state': 1234, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1234, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'C': 31, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=31, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=31, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (816,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9581393536837052, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1234, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(816,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
      "             momentum=0.9581393536837052, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(816,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
      "             momentum=0.9581393536837052, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1234, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1234}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 34, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1234, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [1.         0.33333333 1.         0.33333333 0.25       0.5699888 ]]\n",
      "y_train: [34.58333335 41.15555559]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed1234_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N86, Seed12345 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 86\n",
      "len(X_test): 15539\n",
      "len(y_train): 86\n",
      "len(y_test): 15539\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[7.22600000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 7.13266762e-02 3.63833334e+01]\n",
      " [7.98200000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 6.66666667e-01 6.19115549e-01 3.25999999e+01]]\n",
      "X_test: [[9.59200000e+03 2.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.56633381e-02 1.53333333e+01]\n",
      " [8.81300000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.54778887e-01 3.92833333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=12345,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=12345,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=12345, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=12345), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(483,), (486, 286), (130, 421, 426)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.20456028, 0.56772503, 0.5955447 , 0.96451452, 0.6531771 ,\n",
      "       0.74890664, 0.65356987, 0.74771481, 0.96130674, 0.0083883 ,\n",
      "       0.10644438, 0.29870371, 0.65641118, 0.80981255, 0.87217591,\n",
      "       0.9646476 , 0.72368535, 0.64247533, 0.71745362, 0.46759901,\n",
      "       0.32558468, 0.43964461, 0.72968908, 0.99401459, 0.67687371,\n",
      "       0.79082252, 0.17091426, 0.02684928, 0.80037024, 0.90372254,\n",
      "       0.02467621, 0.49174732, 0.52625517, 0.59636601, 0.05195755,\n",
      "       0.89508953, 0.72826618, 0.81835001, 0.50022275, 0.81018941,\n",
      "       0.09596853, 0.21895004, 0.25871906, 0.46810575, 0.4593732 ,\n",
      "       0.70950978, 0.17805301, 0.53144988, 0.16774223, 0.76881392]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'squared_loss', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 12345, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 12345, 'selection': 'random', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 49, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 39, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 12345, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 21, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (483,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.49174731844588593, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 12345, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(483,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.49174731844588593, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(483,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.49174731844588593, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 22, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 12345}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 20, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 31, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 12345, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]\n",
      " [0.4        1.         1.         1.         0.66666667 0.61911555]]\n",
      "y_train: [36.85000002 32.88888888]\n",
      "X_test: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.6        0.33333333 1.         1.         0.33333333 0.65477889]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n86_seed12345_DummyRegressor.joblib \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_predictions_imagenet16_120_200epochs_n86.csv \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_fit_times_imagenet16_120_200epochs_n86.csv \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed0 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.18700000e+04 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 2.90849673e-01 3.93999999e+01]\n",
      " [7.36500000e+03 1.66666667e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 2.72331155e-02 8.33333332e-01]]\n",
      "X_test: [[4.41400000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.63616558e-01 1.68666667e+01]\n",
      " [1.41830000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.27233115e-01 3.46333333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=0,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=0), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=0, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(685,), (560, 630), (193, 836, 764)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.54488318, 0.4236548 , 0.64589411, 0.43758721, 0.891773  ,\n",
      "       0.96366276, 0.38344152, 0.79172504, 0.52889492, 0.56804456,\n",
      "       0.92559664, 0.07103606, 0.0871293 , 0.0202184 , 0.83261985,\n",
      "       0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
      "       0.78052918, 0.11827443, 0.63992102, 0.14335329, 0.94466892,\n",
      "       0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
      "       0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
      "       0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
      "       0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
      "       0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 1000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 0, 'selection': 'random', 'tol': 1e-05, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=0,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=1000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=0,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 29, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=29, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=29, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (193, 836, 764), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6667667154456677, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.         0.02723312]]\n",
      "y_train: [38.89999989  0.83333333]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed0_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed1 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.44850000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.43001120e-01 8.33333333e-01]\n",
      " [4.05900000e+03 2.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 7.50000000e-01 2.79955207e-02 1.59500000e+01]]\n",
      "X_test: [[1.43700000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.43001120e-01 3.95777777e+01]\n",
      " [1.40900000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 5.59910414e-02 2.82555555e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(38,), (236, 73), (768, 716, 646)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.14675589, 0.09233859, 0.18626021, 0.34556073, 0.39676747,\n",
      "       0.53881673, 0.41919451, 0.6852195 , 0.20445225, 0.87811744,\n",
      "       0.02738759, 0.67046751, 0.4173048 , 0.55868983, 0.14038694,\n",
      "       0.19810149, 0.80074457, 0.96826158, 0.31342418, 0.69232262,\n",
      "       0.87638915, 0.89460666, 0.08504421, 0.03905478, 0.16983042,\n",
      "       0.8781425 , 0.09834683, 0.42110763, 0.95788953, 0.53316528,\n",
      "       0.69187711, 0.31551563, 0.68650093, 0.83462567, 0.01828828,\n",
      "       0.75014431, 0.98886109, 0.74816565, 0.28044399, 0.78927933,\n",
      "       0.10322601, 0.44789353, 0.9085955 , 0.29361415, 0.28777534,\n",
      "       0.13002857, 0.01936696, 0.67883553, 0.21162812, 0.26554666]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.4191945144032948, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.4191945144032948, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 44, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "X_train: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.75       0.02799552]]\n",
      "y_train: [ 0.83333333 16.86666664]\n",
      "X_test: [[0.2        1.         1.         1.         0.25       0.24300112]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed10 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.39360000e+04 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.19115549e-01 3.68555555e+01]\n",
      " [1.36200000e+03 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 6.90442225e-01 4.29333332e+01]]\n",
      "X_test: [[8.96300000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 9.28673324e-01 1.77333333e+01]\n",
      " [4.03800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 7.13266762e-02 3.54555556e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=10,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=10,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=10), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(266,), (126, 528), (321, 370, 124)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.83191136, 0.58332174, 0.02517173, 0.70920801, 0.26556613,\n",
      "       0.26360285, 0.15037787, 0.68381843, 0.81660184, 0.33607158,\n",
      "       0.89081653, 0.19812181, 0.03061665, 0.87761494, 0.72743551,\n",
      "       0.54088093, 0.13145815, 0.41366737, 0.77872881, 0.58390137,\n",
      "       0.18263144, 0.82608225, 0.10540183, 0.28357668, 0.06556327,\n",
      "       0.05644419, 0.76545582, 0.01178803, 0.61194334, 0.33188226,\n",
      "       0.55964837, 0.33549965, 0.41118255, 0.0768555 , 0.85304299,\n",
      "       0.43998746, 0.12195415, 0.73173462, 0.13878247, 0.76688005,\n",
      "       0.83198977, 0.30977806, 0.59758229, 0.87239246, 0.98302087,\n",
      "       0.46740328, 0.87574449, 0.2960687 , 0.13129105, 0.84281793]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 10, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 10, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 10, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 22, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (321, 370, 124), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 3000, 'momentum': 0.06556326635477827, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 10, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'square', 'n_estimators': 450, 'random_state': 10}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 14, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 29, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 10, 'presort': 'deprecated', 'random_state': 10, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.4        1.         1.         1.         0.33333333 0.61911555]\n",
      " [0.8        0.33333333 1.         0.33333333 0.         0.69044223]]\n",
      "y_train: [36.83333332 42.01111108]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed10_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed42 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.40000000e+01 1.00000000e+00 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 6.46082949e-01 4.08666666e+01]\n",
      " [1.20760000e+04 1.00000000e+00 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 8.23041475e-01 4.20333334e+01]]\n",
      "X_test: [[1.35140000e+04 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 4.46082949e-01 3.56999999e+01]\n",
      " [6.70500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 6.00000000e-01 2.23041475e-01 2.88666666e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=42,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(103,), (436, 861), (271, 107, 72)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.59865848, 0.15601864, 0.15599452, 0.05808361, 0.86617615,\n",
      "       0.60111501, 0.70807258, 0.02058449, 0.96990985, 0.83244264,\n",
      "       0.21233911, 0.18182497, 0.18340451, 0.30424224, 0.52475643,\n",
      "       0.43194502, 0.29122914, 0.61185289, 0.13949386, 0.29214465,\n",
      "       0.36636184, 0.45606998, 0.78517596, 0.19967378, 0.51423444,\n",
      "       0.59241457, 0.04645041, 0.60754485, 0.17052412, 0.06505159,\n",
      "       0.94888554, 0.96563203, 0.80839735, 0.30461377, 0.09767211,\n",
      "       0.68423303, 0.44015249, 0.12203823, 0.49517691, 0.03438852,\n",
      "       0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802,\n",
      "       0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 42, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'random', 'tol': 0.001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 36, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (103,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 135000, 'max_iter': 9000, 'momentum': 0.2587799816000169, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.2587799816000169, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=135000, max_iter=9000,\n",
      "             momentum=0.2587799816000169, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 22, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': True, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 150, 'random_state': 42}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 15, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[1.         0.33333333 1.         1.         0.2        0.64608295]\n",
      " [1.         0.33333333 1.         1.         0.         0.82304147]]\n",
      "y_train: [40.74444437 40.26666669]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed42_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed100 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[9.91100000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 5.00000000e-01 2.36383442e-01 2.13166666e+01]\n",
      " [1.10020000e+04 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 5.00000000e-01 2.36383442e-01 2.38999999e+01]]\n",
      "X_test: [[3.28900000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.63616558e-01 3.97444443e+01]\n",
      " [4.82500000e+03 8.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.54466231e-01 4.32499999e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=100, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=100), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=100, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(521,), (793, 836), (872, 856, 80)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.84477613, 0.00471886, 0.12156912, 0.67074908, 0.82585276,\n",
      "       0.13670659, 0.57509333, 0.89132195, 0.20920212, 0.18532822,\n",
      "       0.10837689, 0.21969749, 0.97862378, 0.81168315, 0.17194101,\n",
      "       0.81622475, 0.27407375, 0.43170418, 0.94002982, 0.81764938,\n",
      "       0.33611195, 0.17541045, 0.37283205, 0.00568851, 0.25242635,\n",
      "       0.79566251, 0.01525497, 0.59884338, 0.60380454, 0.10514769,\n",
      "       0.38194344, 0.03647606, 0.89041156, 0.98092086, 0.05994199,\n",
      "       0.89054594, 0.5769015 , 0.74247969, 0.63018394, 0.58184219,\n",
      "       0.02043913, 0.21002658, 0.54468488, 0.76911517, 0.25069523,\n",
      "       0.28589569, 0.85239509, 0.97500649, 0.88485329, 0.35950784]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 100, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 100, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 24, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 100, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (793, 836), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.8905459447285041, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 100, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 16, 'min_samples_split': 17, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 100, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 50, 'random_state': 100}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 48, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 100, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.16666667 1.         1.         1.         0.5        0.23638344]]\n",
      "y_train: [22.03333333 24.09999998]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed100_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed123 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.43100000e+04 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 2.36383442e-01 3.93222221e+01]\n",
      " [9.23000000e+03 1.66666667e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 2.72331155e-02 2.76000000e+01]]\n",
      "X_test: [[2.43000000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 5.00000000e-01 2.36383442e-01 2.75444444e+01]\n",
      " [1.49400000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 5.00000000e-01 3.80777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=123,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=123,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=123, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=123), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=123, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(511,), (366, 383), (323, 99, 743)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.71915031, 0.49111893, 0.78002776, 0.41092437, 0.5796943 ,\n",
      "       0.13995076, 0.40101756, 0.62731701, 0.32415089, 0.24475928,\n",
      "       0.69475518, 0.5939024 , 0.63179202, 0.44025718, 0.08372648,\n",
      "       0.71233018, 0.42786349, 0.2977805 , 0.49208478, 0.74029639,\n",
      "       0.35772892, 0.41720995, 0.65472131, 0.37380143, 0.23451288,\n",
      "       0.98799529, 0.76599595, 0.77700444, 0.02798196, 0.17390652,\n",
      "       0.15408224, 0.07708648, 0.8898657 , 0.7503787 , 0.69340324,\n",
      "       0.51176338, 0.46426806, 0.56843069, 0.30254945, 0.49730879,\n",
      "       0.68326291, 0.91669867, 0.10892895, 0.49549179, 0.23283593,\n",
      "       0.43686066, 0.75154299, 0.48089213, 0.79772841, 0.28270293]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 123, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 47, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (366, 383), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.4920847767923423, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 38, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 123}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 46, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 123, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='huber',\n",
      "                          max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=46, min_samples_split=42,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.16666667 1.         1.         1.         0.         0.23638344]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [39.06666656 28.83333332]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed123_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed666 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[5.11200000e+03 3.33333333e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 5.97796143e-01 3.94222223e+01]\n",
      " [6.68000000e+02 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 3.33333333e-01 3.00833333e+01]]\n",
      "X_test: [[7.37700000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 6.88705234e-02 2.87000000e+01]\n",
      " [6.01100000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.98898072e-01 3.92777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=666,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=666,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=666, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=666), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(237,), (899, 430), (831, 71, 415)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.95145796, 0.0127032 , 0.4135877 , 0.04881279, 0.09992856,\n",
      "       0.50806631, 0.20024754, 0.74415417, 0.192892  , 0.70084475,\n",
      "       0.29322811, 0.77447945, 0.00510884, 0.11285765, 0.11095367,\n",
      "       0.24766823, 0.0232363 , 0.72732115, 0.34003494, 0.19750316,\n",
      "       0.90917959, 0.97834699, 0.53280254, 0.25913185, 0.58381262,\n",
      "       0.32569065, 0.88889931, 0.62640453, 0.81887369, 0.54734542,\n",
      "       0.41671201, 0.74304719, 0.36959638, 0.07516654, 0.77519298,\n",
      "       0.21940924, 0.07934213, 0.48678052, 0.1536739 , 0.82846513,\n",
      "       0.19136857, 0.27040895, 0.56103442, 0.90238039, 0.85178834,\n",
      "       0.41808196, 0.39347627, 0.01622051, 0.29921337, 0.35377822]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 666, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 666, 'selection': 'random', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 8, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 22, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 48, 'min_samples_split': 35, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 666, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (831, 71, 415), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.0751665439471918, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 666, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 19, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 666, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 666}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.01, 'loss': 'lad', 'max_depth': 19, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 666, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.         0.59779614]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.5        0.33333333]]\n",
      "y_train: [39.78888885 30.08333332]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.06887052]\n",
      " [0.16666667 1.         1.         1.         0.25       0.29889807]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed666_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed1000 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[4.31500000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 4.00000000e-01 4.86002240e-01 1.34666666e+01]\n",
      " [2.46800000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 4.00000000e-01 2.70996641e-01 2.35888888e+01]]\n",
      "X_test: [[8.32500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.70996641e-01 3.49222221e+01]\n",
      " [1.41650000e+04 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 4.00000000e-01 2.98992161e-01 3.65888888e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1000,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1000, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1000, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1000), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(436,), (600, 72), (705, 252, 351)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.4821914 , 0.87247454, 0.21233268, 0.04070962, 0.39719446,\n",
      "       0.2331322 , 0.84174072, 0.20708234, 0.74246953, 0.39215413,\n",
      "       0.18225652, 0.74353941, 0.06958208, 0.8853372 , 0.9526444 ,\n",
      "       0.93114343, 0.41543095, 0.02898166, 0.98202748, 0.33963768,\n",
      "       0.70668719, 0.36187707, 0.0351059 , 0.85505825, 0.65725351,\n",
      "       0.76568299, 0.55408724, 0.88509294, 0.90419762, 0.0104217 ,\n",
      "       0.07455674, 0.24462921, 0.13330475, 0.6979251 , 0.39820488,\n",
      "       0.88312219, 0.18100751, 0.43249917, 0.0181432 , 0.69143786,\n",
      "       0.46969065, 0.12822219, 0.89133705, 0.91820362, 0.07312099,\n",
      "       0.04544794, 0.4385729 , 0.60172093, 0.31022703, 0.68190824]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 1000, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1000, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=True, positive=True, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 25, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=25, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=25, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 30, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1000, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 25, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (600, 72), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.7656829941452387, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1000, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 1000, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50, 'random_state': 1000}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.1, 'loss': 'lad', 'max_depth': 49, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 30, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1000, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.48600224]\n",
      " [0.4        0.33333333 1.         0.33333333 0.4        0.27099664]]\n",
      "y_train: [13.43333331 24.34444444]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1000_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed1234 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.26340000e+04 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 2.98992161e-01 3.81666666e+01]\n",
      " [1.50970000e+04 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.70996641e-01 3.14666666e+01]]\n",
      "X_test: [[5.76300000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 4.86002240e-01 2.80000000e+01]\n",
      " [2.81500000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.98992161e-01 3.98222222e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1234,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1234,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1234), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(816,), (724, 295), (54, 205, 373)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.78535858, 0.77997581, 0.27259261, 0.27646426, 0.80187218,\n",
      "       0.95813935, 0.87593263, 0.35781727, 0.50099513, 0.68346294,\n",
      "       0.71270203, 0.37025075, 0.56119619, 0.50308317, 0.01376845,\n",
      "       0.77282662, 0.88264119, 0.36488598, 0.61539618, 0.07538124,\n",
      "       0.36882401, 0.9331401 , 0.65137814, 0.39720258, 0.78873014,\n",
      "       0.31683612, 0.56809865, 0.86912739, 0.43617342, 0.80214764,\n",
      "       0.14376682, 0.70426097, 0.70458131, 0.21879211, 0.92486763,\n",
      "       0.44214076, 0.90931596, 0.05980922, 0.18428708, 0.04735528,\n",
      "       0.67488094, 0.59462478, 0.53331016, 0.04332406, 0.56143308,\n",
      "       0.32966845, 0.50296683, 0.11189432, 0.60719371, 0.56594464]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1234, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': False, 'positive': True, 'precompute': False, 'random_state': 1234, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1234, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (816,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9581393536837052, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1234, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(816,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
      "             momentum=0.9581393536837052, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(816,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
      "             momentum=0.9581393536837052, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1234, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1234}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 34, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1234, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "X_train: [[0.6        0.33333333 1.         0.33333333 0.5        0.29899216]\n",
      " [0.4        0.33333333 1.         0.33333333 0.25       0.27099664]]\n",
      "y_train: [38.38333333 30.73333332]\n",
      "X_test: [[0.4        1.         1.         1.         0.25       0.48600224]\n",
      " [0.6        0.33333333 1.         0.33333333 0.25       0.29899216]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed1234_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N129, Seed12345 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 129\n",
      "len(X_test): 15496\n",
      "len(y_train): 129\n",
      "len(y_test): 15496\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[2.16400000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 6.88705234e-02 3.38888888e+01]\n",
      " [1.68200000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.32231405e-01 3.86333333e+01]]\n",
      "X_test: [[9.59200000e+03 1.66666667e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.44352617e-02 1.53333333e+01]\n",
      " [8.81300000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.32231405e-01 3.92833333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=12345,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=12345,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=12345, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=12345), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(483,), (486, 286), (130, 421, 426)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.20456028, 0.56772503, 0.5955447 , 0.96451452, 0.6531771 ,\n",
      "       0.74890664, 0.65356987, 0.74771481, 0.96130674, 0.0083883 ,\n",
      "       0.10644438, 0.29870371, 0.65641118, 0.80981255, 0.87217591,\n",
      "       0.9646476 , 0.72368535, 0.64247533, 0.71745362, 0.46759901,\n",
      "       0.32558468, 0.43964461, 0.72968908, 0.99401459, 0.67687371,\n",
      "       0.79082252, 0.17091426, 0.02684928, 0.80037024, 0.90372254,\n",
      "       0.02467621, 0.49174732, 0.52625517, 0.59636601, 0.05195755,\n",
      "       0.89508953, 0.72826618, 0.81835001, 0.50022275, 0.81018941,\n",
      "       0.09596853, 0.21895004, 0.25871906, 0.46810575, 0.4593732 ,\n",
      "       0.70950978, 0.17805301, 0.53144988, 0.16774223, 0.76881392]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'squared_loss', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 12345, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 12345, 'selection': 'random', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 49, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 39, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 12345, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 21, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (483,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.49174731844588593, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 12345, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(483,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.49174731844588593, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(483,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.49174731844588593, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 22, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 12345}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 20, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 31, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 12345, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_train: [33.9777777  39.14444444]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n129_seed12345_DummyRegressor.joblib \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_predictions_imagenet16_120_200epochs_n129.csv \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_fit_times_imagenet16_120_200epochs_n129.csv \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed0 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.92200000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 2.90849673e-01 3.68833332e+01]\n",
      " [7.20400000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 5.44662309e-02 3.30833332e+01]]\n",
      "X_test: [[4.41400000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.63616558e-01 1.68666667e+01]\n",
      " [1.41830000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.27233115e-01 3.46333333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=0,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=0), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=0, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(685,), (560, 630), (193, 836, 764)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.54488318, 0.4236548 , 0.64589411, 0.43758721, 0.891773  ,\n",
      "       0.96366276, 0.38344152, 0.79172504, 0.52889492, 0.56804456,\n",
      "       0.92559664, 0.07103606, 0.0871293 , 0.0202184 , 0.83261985,\n",
      "       0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
      "       0.78052918, 0.11827443, 0.63992102, 0.14335329, 0.94466892,\n",
      "       0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
      "       0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
      "       0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
      "       0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
      "       0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 24, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (193, 836, 764), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6667667154456677, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.5        0.29084967]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.05446623]]\n",
      "y_train: [37.44999996 33.69999996]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed0_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed1 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[5.98400000e+03 4.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 4.00000000e-01 4.00000000e-01 3.49111110e+01]\n",
      " [7.86200000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 2.46082949e-01 3.60555556e+01]]\n",
      "X_test: [[1.43700000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 2.00000000e-01 3.95777777e+01]\n",
      " [1.40900000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 4.60829493e-02 2.82555555e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(38,), (236, 73), (768, 716, 646)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.14675589, 0.09233859, 0.18626021, 0.34556073, 0.39676747,\n",
      "       0.53881673, 0.41919451, 0.6852195 , 0.20445225, 0.87811744,\n",
      "       0.02738759, 0.67046751, 0.4173048 , 0.55868983, 0.14038694,\n",
      "       0.19810149, 0.80074457, 0.96826158, 0.31342418, 0.69232262,\n",
      "       0.87638915, 0.89460666, 0.08504421, 0.03905478, 0.16983042,\n",
      "       0.8781425 , 0.09834683, 0.42110763, 0.95788953, 0.53316528,\n",
      "       0.69187711, 0.31551563, 0.68650093, 0.83462567, 0.01828828,\n",
      "       0.75014431, 0.98886109, 0.74816565, 0.28044399, 0.78927933,\n",
      "       0.10322601, 0.44789353, 0.9085955 , 0.29361415, 0.28777534,\n",
      "       0.13002857, 0.01936696, 0.67883553, 0.21162812, 0.26554666]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 1, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=1, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=1, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 18, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=18, min_samples_split=46,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=18, min_samples_split=46,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.8781174363909454, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.8781174363909454, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.8781174363909454, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 44, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "X_train: [[0.4        1.         1.         1.         0.4        0.4       ]\n",
      " [0.6        0.33333333 1.         0.33333333 0.2        0.24608295]]\n",
      "y_train: [34.89999993 37.04444435]\n",
      "X_test: [[0.2        1.         1.         1.         0.2        0.2       ]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed10 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[2.11000000e+03 2.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.56633381e-02 2.57111111e+01]\n",
      " [1.10600000e+03 2.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.56633381e-02 2.65777778e+01]]\n",
      "X_test: [[8.96300000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 9.28673324e-01 1.77333333e+01]\n",
      " [4.03800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 7.13266762e-02 3.54555556e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=10,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=10,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=10), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(266,), (126, 528), (321, 370, 124)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.83191136, 0.58332174, 0.02517173, 0.70920801, 0.26556613,\n",
      "       0.26360285, 0.15037787, 0.68381843, 0.81660184, 0.33607158,\n",
      "       0.89081653, 0.19812181, 0.03061665, 0.87761494, 0.72743551,\n",
      "       0.54088093, 0.13145815, 0.41366737, 0.77872881, 0.58390137,\n",
      "       0.18263144, 0.82608225, 0.10540183, 0.28357668, 0.06556327,\n",
      "       0.05644419, 0.76545582, 0.01178803, 0.61194334, 0.33188226,\n",
      "       0.55964837, 0.33549965, 0.41118255, 0.0768555 , 0.85304299,\n",
      "       0.43998746, 0.12195415, 0.73173462, 0.13878247, 0.76688005,\n",
      "       0.83198977, 0.30977806, 0.59758229, 0.87239246, 0.98302087,\n",
      "       0.46740328, 0.87574449, 0.2960687 , 0.13129105, 0.84281793]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 10, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 10, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 10, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 48, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=48, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=48, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (321, 370, 124), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 3000, 'momentum': 0.06556326635477827, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 10, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'square', 'n_estimators': 450, 'random_state': 10}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 14, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 29, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 10, 'presort': 'deprecated', 'random_state': 10, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]\n",
      " [0.2        0.33333333 0.33333333 0.33333333 0.66666667 0.03566334]]\n",
      "y_train: [26.29999995 27.72222217]\n",
      "X_test: [[0.6        1.         1.         1.         0.33333333 0.92867332]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.33333333 0.07132668]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed10_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed42 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[8.11000000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 6.00000000e-01 4.15333333e+01]\n",
      " [1.49480000e+04 2.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 2.00000000e-01 8.33333332e-01]]\n",
      "X_test: [[1.35140000e+04 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 4.46082949e-01 3.56999999e+01]\n",
      " [6.70500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 6.00000000e-01 2.23041475e-01 2.88666666e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=42,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(103,), (436, 861), (271, 107, 72)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.59865848, 0.15601864, 0.15599452, 0.05808361, 0.86617615,\n",
      "       0.60111501, 0.70807258, 0.02058449, 0.96990985, 0.83244264,\n",
      "       0.21233911, 0.18182497, 0.18340451, 0.30424224, 0.52475643,\n",
      "       0.43194502, 0.29122914, 0.61185289, 0.13949386, 0.29214465,\n",
      "       0.36636184, 0.45606998, 0.78517596, 0.19967378, 0.51423444,\n",
      "       0.59241457, 0.04645041, 0.60754485, 0.17052412, 0.06505159,\n",
      "       0.94888554, 0.96563203, 0.80839735, 0.30461377, 0.09767211,\n",
      "       0.68423303, 0.44015249, 0.12203823, 0.49517691, 0.03438852,\n",
      "       0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802,\n",
      "       0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 42, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'random', 'tol': 0.001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 17, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 45, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=17,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=45,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='random')\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=17,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=45,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 36, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (103,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.9695846277645586, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 22, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': True, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 450, 'random_state': 42}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=450, random_state=42)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='exponential',\n",
      "                  n_estimators=450, random_state=42)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 15, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.6 1.  1.  1.  0.2 0.6]\n",
      " [0.2 1.  1.  1.  0.2 0.2]]\n",
      "y_train: [41.83333323  0.83333333]\n",
      "X_test: [[0.8        0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.4        0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed42_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed100 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.33790000e+04 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 5.00000000e-01 4.22000000e+01]\n",
      " [8.17200000e+03 1.66666667e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 2.72331155e-02 3.36333333e+01]]\n",
      "X_test: [[3.28900000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.63616558e-01 3.97444443e+01]\n",
      " [4.82500000e+03 8.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.54466231e-01 4.32499999e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=100, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=100), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=100, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(521,), (793, 836), (872, 856, 80)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.84477613, 0.00471886, 0.12156912, 0.67074908, 0.82585276,\n",
      "       0.13670659, 0.57509333, 0.89132195, 0.20920212, 0.18532822,\n",
      "       0.10837689, 0.21969749, 0.97862378, 0.81168315, 0.17194101,\n",
      "       0.81622475, 0.27407375, 0.43170418, 0.94002982, 0.81764938,\n",
      "       0.33611195, 0.17541045, 0.37283205, 0.00568851, 0.25242635,\n",
      "       0.79566251, 0.01525497, 0.59884338, 0.60380454, 0.10514769,\n",
      "       0.38194344, 0.03647606, 0.89041156, 0.98092086, 0.05994199,\n",
      "       0.89054594, 0.5769015 , 0.74247969, 0.63018394, 0.58184219,\n",
      "       0.02043913, 0.21002658, 0.54468488, 0.76911517, 0.25069523,\n",
      "       0.28589569, 0.85239509, 0.97500649, 0.88485329, 0.35950784]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 100, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 100, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 24, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 100, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'C': 34, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=34, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (793, 836), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.8905459447285041, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 100, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(793, 836), learning_rate='invscaling',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.8905459447285041, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=100,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 16, 'min_samples_split': 17, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 100, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=16,\n",
      "                      min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 50, 'random_state': 100}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
      "                  n_estimators=50, random_state=100)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 48, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 100, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=48,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=46,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=100, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.5        0.33333333 1.         1.         0.25       0.5       ]\n",
      " [0.16666667 0.33333333 0.33333333 0.33333333 0.25       0.02723312]]\n",
      "y_train: [41.98333327 33.86666665]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.25       0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed100_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed123 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[8.51500000e+03 5.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 7.09150327e-01 3.07999999e+01]\n",
      " [1.99600000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 5.00000000e-01 3.90111110e+01]]\n",
      "X_test: [[2.43000000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 5.00000000e-01 2.36383442e-01 2.75444444e+01]\n",
      " [1.49400000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 5.00000000e-01 3.80777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=123,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=123,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=123, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=123), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=123, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(511,), (366, 383), (323, 99, 743)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.71915031, 0.49111893, 0.78002776, 0.41092437, 0.5796943 ,\n",
      "       0.13995076, 0.40101756, 0.62731701, 0.32415089, 0.24475928,\n",
      "       0.69475518, 0.5939024 , 0.63179202, 0.44025718, 0.08372648,\n",
      "       0.71233018, 0.42786349, 0.2977805 , 0.49208478, 0.74029639,\n",
      "       0.35772892, 0.41720995, 0.65472131, 0.37380143, 0.23451288,\n",
      "       0.98799529, 0.76599595, 0.77700444, 0.02798196, 0.17390652,\n",
      "       0.15408224, 0.07708648, 0.8898657 , 0.7503787 , 0.69340324,\n",
      "       0.51176338, 0.46426806, 0.56843069, 0.30254945, 0.49730879,\n",
      "       0.68326291, 0.91669867, 0.10892895, 0.49549179, 0.23283593,\n",
      "       0.43686066, 0.75154299, 0.48089213, 0.79772841, 0.28270293]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=123, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=123, selection='cyclic',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'brute', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='brute', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 123, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=4,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=45, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=123, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 47, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=47, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (366, 383), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 3000, 'momentum': 0.4920847767923423, 'n_iter_no_change': 30, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(366, 383), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=3000,\n",
      "             momentum=0.4920847767923423, n_iter_no_change=30,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 38, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=27,\n",
      "                      min_samples_split=38, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "                      random_state=123, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 123}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=123)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 13, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 31, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 123, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=13,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=31, min_samples_split=25,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=13,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=31, min_samples_split=25,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=123, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.5        1.         1.         1.         0.25       0.70915033]\n",
      " [0.5        0.33333333 1.         1.         0.         0.5       ]]\n",
      "y_train: [31.16666666 38.61111103]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.5        0.23638344]\n",
      " [0.5        0.33333333 1.         1.         0.25       0.5       ]]\n",
      "y_test: [27.56666658 38.97777771] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed123_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed666 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.05740000e+04 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.98992161e-01 4.20166665e+01]\n",
      " [1.44930000e+04 8.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 1.00000000e+00 3.85444444e+01]]\n",
      "X_test: [[7.37700000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 5.59910414e-02 2.87000000e+01]\n",
      " [6.01100000e+03 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 2.43001120e-01 3.92777777e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=666,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=666,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=666, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=666), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(237,), (899, 430), (831, 71, 415)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.95145796, 0.0127032 , 0.4135877 , 0.04881279, 0.09992856,\n",
      "       0.50806631, 0.20024754, 0.74415417, 0.192892  , 0.70084475,\n",
      "       0.29322811, 0.77447945, 0.00510884, 0.11285765, 0.11095367,\n",
      "       0.24766823, 0.0232363 , 0.72732115, 0.34003494, 0.19750316,\n",
      "       0.90917959, 0.97834699, 0.53280254, 0.25913185, 0.58381262,\n",
      "       0.32569065, 0.88889931, 0.62640453, 0.81887369, 0.54734542,\n",
      "       0.41671201, 0.74304719, 0.36959638, 0.07516654, 0.77519298,\n",
      "       0.21940924, 0.07934213, 0.48678052, 0.1536739 , 0.82846513,\n",
      "       0.19136857, 0.27040895, 0.56103442, 0.90238039, 0.85178834,\n",
      "       0.41808196, 0.39347627, 0.01622051, 0.29921337, 0.35377822]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 666, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=5, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=666, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 666, 'selection': 'random', 'tol': 0.0001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=666, selection='random',\n",
      "      tol=0.0001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=10, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=10, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 22, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 48, 'min_samples_split': 35, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 666, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=22,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=48, min_samples_split=35,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=666, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 35, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=35, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (831, 71, 415), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.0751665439471918, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 666, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(831, 71, 415), learning_rate='constant',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.0751665439471918, n_iter_no_change=10,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=666,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 19, 'min_samples_split': 33, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 666, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=19,\n",
      "                      min_samples_split=33, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=666, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 666}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=666)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.01, 'loss': 'lad', 'max_depth': 19, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 27, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 666, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.01, loss='lad', max_depth=19,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=27, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=666, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.25       0.29899216]\n",
      " [0.83333333 0.33333333 1.         1.         0.25       1.        ]]\n",
      "y_train: [42.83333326 37.75555549]\n",
      "X_test: [[0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05599104]\n",
      " [0.16666667 1.         1.         1.         0.25       0.24300112]]\n",
      "y_test: [29.26666662 39.11111112] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed666_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed1000 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.31090000e+04 8.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 7.56998880e-01 4.25999999e+01]\n",
      " [2.20800000e+03 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 5.13997760e-01 3.95777777e+01]]\n",
      "X_test: [[8.32500000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.70996641e-01 3.49222221e+01]\n",
      " [1.41650000e+04 6.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 4.00000000e-01 2.98992161e-01 3.65888888e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1000,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1000,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1000, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1000, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1000), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(436,), (600, 72), (705, 252, 351)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.4821914 , 0.87247454, 0.21233268, 0.04070962, 0.39719446,\n",
      "       0.2331322 , 0.84174072, 0.20708234, 0.74246953, 0.39215413,\n",
      "       0.18225652, 0.74353941, 0.06958208, 0.8853372 , 0.9526444 ,\n",
      "       0.93114343, 0.41543095, 0.02898166, 0.98202748, 0.33963768,\n",
      "       0.70668719, 0.36187707, 0.0351059 , 0.85505825, 0.65725351,\n",
      "       0.76568299, 0.55408724, 0.88509294, 0.90419762, 0.0104217 ,\n",
      "       0.07455674, 0.24462921, 0.13330475, 0.6979251 , 0.39820488,\n",
      "       0.88312219, 0.18100751, 0.43249917, 0.0181432 , 0.69143786,\n",
      "       0.46969065, 0.12822219, 0.89133705, 0.91820362, 0.07312099,\n",
      "       0.04544794, 0.4385729 , 0.60172093, 0.31022703, 0.68190824]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 1000, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l2', power_t=0.25,\n",
      "             random_state=1000, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': False, 'max_iter': 3000, 'normalize': False, 'positive': True, 'precompute': False, 'random_state': 1000, 'selection': 'random', 'tol': 1e-05, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1000,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1000,\n",
      "      selection='random', tol=1e-05, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 18, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=18, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=18, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 30, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1000, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=30,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=18,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1000, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 25, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=25, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (600, 72), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.7656829941452387, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1000, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(600, 72), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.7656829941452387, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1000,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 1000, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=20,\n",
      "                      min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1000, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50, 'random_state': 1000}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=50, random_state=1000)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.1, 'loss': 'lad', 'max_depth': 49, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 30, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1000, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.1, loss='lad', max_depth=49,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=30, min_samples_split=6,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1000, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.8        0.33333333 1.         1.         0.2        0.75699888]\n",
      " [0.6        0.33333333 1.         1.         0.         0.51399776]]\n",
      "y_train: [40.79999997 39.82222217]\n",
      "X_test: [[0.4        0.33333333 1.         0.33333333 0.         0.27099664]\n",
      " [0.6        0.33333333 1.         0.33333333 0.4        0.29899216]]\n",
      "y_test: [35.35555548 36.26666668] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1000_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed1234 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.19000000e+02 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 5.00000000e-01 5.44662309e-02 3.67777777e+01]\n",
      " [3.47200000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50000000e-01 0.00000000e+00 2.07666666e+01]]\n",
      "X_test: [[5.76300000e+03 3.33333333e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 4.72766885e-01 2.80000000e+01]\n",
      " [2.81500000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.90849673e-01 3.98222222e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1234,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1234,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1234), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(816,), (724, 295), (54, 205, 373)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.78535858, 0.77997581, 0.27259261, 0.27646426, 0.80187218,\n",
      "       0.95813935, 0.87593263, 0.35781727, 0.50099513, 0.68346294,\n",
      "       0.71270203, 0.37025075, 0.56119619, 0.50308317, 0.01376845,\n",
      "       0.77282662, 0.88264119, 0.36488598, 0.61539618, 0.07538124,\n",
      "       0.36882401, 0.9331401 , 0.65137814, 0.39720258, 0.78873014,\n",
      "       0.31683612, 0.56809865, 0.86912739, 0.43617342, 0.80214764,\n",
      "       0.14376682, 0.70426097, 0.70458131, 0.21879211, 0.92486763,\n",
      "       0.44214076, 0.90931596, 0.05980922, 0.18428708, 0.04735528,\n",
      "       0.67488094, 0.59462478, 0.53331016, 0.04332406, 0.56143308,\n",
      "       0.32966845, 0.50296683, 0.11189432, 0.60719371, 0.56594464]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': False, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'epsilon_insensitive', 'max_iter': 3000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1234, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='epsilon_insensitive',\n",
      "             max_iter=3000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1234, shuffle=True, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': False, 'positive': True, 'precompute': False, 'random_state': 1234, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000,\n",
      "      normalize=False, positive=True, precompute=False, random_state=1234,\n",
      "      selection='random', tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 35, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1234, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=35,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=12, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1234, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'C': 31, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=31, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=31, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='poly', max_iter=1000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (54, 205, 373), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 9000, 'momentum': 0.04735527880151513, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1234, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(54, 205, 373), learning_rate='invscaling',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.04735527880151513, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(54, 205, 373), learning_rate='invscaling',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.04735527880151513, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1234,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1234, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1234, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1234}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
      "                  n_estimators=50, random_state=1234)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 34, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 27, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 1234, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='ls', max_depth=34,\n",
      "                          max_features='auto', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=5, min_samples_split=27,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=300,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1234, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'median'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "X_train: [[0.33333333 0.33333333 0.33333333 0.33333333 0.5        0.05446623]\n",
      " [0.         0.         0.         0.         0.25       0.        ]]\n",
      "y_train: [37.03333332 20.9333333 ]\n",
      "X_test: [[0.33333333 1.         1.         1.         0.25       0.47276688]\n",
      " [0.5        0.33333333 1.         0.33333333 0.25       0.29084967]]\n",
      "y_test: [29.36666664 39.19999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='median')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed1234_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N172, Seed12345 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 172\n",
      "len(X_test): 15453\n",
      "len(y_train): 172\n",
      "len(y_test): 15453\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.31600000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 3.67768595e-01 4.30333333e+01]\n",
      " [7.87300000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 3.33333333e-01 6.88705234e-02 3.34000000e+01]]\n",
      "X_test: [[9.59200000e+03 1.66666667e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 6.66666667e-01 3.44352617e-02 1.53333333e+01]\n",
      " [8.81300000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 3.33333333e-01 6.32231405e-01 3.92833333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=12345,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=12345,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=12345, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=12345), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(483,), (486, 286), (130, 421, 426)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.20456028, 0.56772503, 0.5955447 , 0.96451452, 0.6531771 ,\n",
      "       0.74890664, 0.65356987, 0.74771481, 0.96130674, 0.0083883 ,\n",
      "       0.10644438, 0.29870371, 0.65641118, 0.80981255, 0.87217591,\n",
      "       0.9646476 , 0.72368535, 0.64247533, 0.71745362, 0.46759901,\n",
      "       0.32558468, 0.43964461, 0.72968908, 0.99401459, 0.67687371,\n",
      "       0.79082252, 0.17091426, 0.02684928, 0.80037024, 0.90372254,\n",
      "       0.02467621, 0.49174732, 0.52625517, 0.59636601, 0.05195755,\n",
      "       0.89508953, 0.72826618, 0.81835001, 0.50022275, 0.81018941,\n",
      "       0.09596853, 0.21895004, 0.25871906, 0.46810575, 0.4593732 ,\n",
      "       0.70950978, 0.17805301, 0.53144988, 0.16774223, 0.76881392]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'squared_loss', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 12345, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='squared_loss', max_iter=9000,\n",
      "             n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=12345, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 12345, 'selection': 'random', 'tol': 0.0001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=12345, selection='random',\n",
      "      tol=0.0001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=1e-05, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=21, p=2,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': 49, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 39, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 12345, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=49,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=39, min_samples_split=8,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=12345, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 21, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=21, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (130, 421, 426), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 15000, 'max_iter': 9000, 'momentum': 0.5677250290816866, 'n_iter_no_change': 10, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 12345, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(130, 421, 426), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.5677250290816866, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(130, 421, 426), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=15000, max_iter=9000,\n",
      "             momentum=0.5677250290816866, n_iter_no_change=10,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=12345,\n",
      "             shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 22, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=22,\n",
      "                      min_samples_split=34, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=12345, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 450, 'random_state': 12345}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='square',\n",
      "                  n_estimators=450, random_state=12345)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 20, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 14, 'min_samples_split': 31, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 12345, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=20,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=14, min_samples_split=31,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=12345, subsample=0.1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "X_train: [[0.5        0.33333333 1.         0.33333333 0.         0.3677686 ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.06887052]]\n",
      "y_train: [42.22222217 33.74444436]\n",
      "X_test: [[0.16666667 0.33333333 0.33333333 0.33333333 0.66666667 0.03443526]\n",
      " [0.5        0.33333333 1.         1.         0.33333333 0.6322314 ]]\n",
      "y_test: [16.11666667 38.44999992] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n172_seed12345_DummyRegressor.joblib \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_predictions_imagenet16_120_200epochs_n172.csv \n",
      "\n",
      "###### save_results() ######\n",
      "saved file: /home/gean/nns_performance_prediction/results/fast/test12/nasbench201_fit_times_imagenet16_120_200epochs_n172.csv \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N344, Seed0 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 344\n",
      "len(X_test): 15281\n",
      "len(y_train): 344\n",
      "len(y_test): 15281\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[1.36880000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.27233115e-01 4.15444444e+01]\n",
      " [1.55400000e+04 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 5.44662309e-02 3.27166666e+01]]\n",
      "X_test: [[4.41400000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 2.63616558e-01 1.68666667e+01]\n",
      " [1.41830000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.50000000e-01 5.27233115e-01 3.46333333e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=0,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=0), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=0, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(685,), (560, 630), (193, 836, 764)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.54488318, 0.4236548 , 0.64589411, 0.43758721, 0.891773  ,\n",
      "       0.96366276, 0.38344152, 0.79172504, 0.52889492, 0.56804456,\n",
      "       0.92559664, 0.07103606, 0.0871293 , 0.0202184 , 0.83261985,\n",
      "       0.77815675, 0.87001215, 0.97861834, 0.79915856, 0.46147936,\n",
      "       0.78052918, 0.11827443, 0.63992102, 0.14335329, 0.94466892,\n",
      "       0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
      "       0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
      "       0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
      "       0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
      "       0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=15, penalty='l2', power_t=0.25, random_state=0,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 0, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=0, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=3000,\n",
      "              normalize=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=22, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 22, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 20, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 0, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=22,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=0, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 24, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=24, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (193, 836, 764), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.6667667154456677, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 0, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(193, 836, 764), learning_rate='constant',\n",
      "             learning_rate_init=0.01, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.6667667154456677, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "             solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 25, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=25,\n",
      "                      min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50, 'random_state': 0}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
      "                  n_estimators=50, random_state=0)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 0, 'subsample': 0.1, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=15, max_features='auto',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=26,\n",
      "                          min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=900, n_iter_no_change=90,\n",
      "                          presort='deprecated', random_state=0, subsample=0.1,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.25       0.05446623]]\n",
      "y_train: [41.49999984 33.9       ]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.25       0.26361656]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.25       0.52723312]]\n",
      "y_test: [17.55555553 33.63333324] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed0_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N344, Seed1 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 344\n",
      "len(X_test): 15281\n",
      "len(y_train): 344\n",
      "len(y_test): 15281\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.90000000e+02 5.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 6.00000000e-01 4.44500001e+01]\n",
      " [1.33600000e+04 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 4.60829493e-02 3.27499999e+01]]\n",
      "X_test: [[1.43700000e+04 1.66666667e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 2.00000000e-01 3.95777777e+01]\n",
      " [1.40900000e+03 3.33333333e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 4.60829493e-02 2.82555555e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=1,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=1), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=1, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(38,), (236, 73), (768, 716, 646)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.14675589, 0.09233859, 0.18626021, 0.34556073, 0.39676747,\n",
      "       0.53881673, 0.41919451, 0.6852195 , 0.20445225, 0.87811744,\n",
      "       0.02738759, 0.67046751, 0.4173048 , 0.55868983, 0.14038694,\n",
      "       0.19810149, 0.80074457, 0.96826158, 0.31342418, 0.69232262,\n",
      "       0.87638915, 0.89460666, 0.08504421, 0.03905478, 0.16983042,\n",
      "       0.8781425 , 0.09834683, 0.42110763, 0.95788953, 0.53316528,\n",
      "       0.69187711, 0.31551563, 0.68650093, 0.83462567, 0.01828828,\n",
      "       0.75014431, 0.98886109, 0.74816565, 0.28044399, 0.78927933,\n",
      "       0.10322601, 0.44789353, 0.9085955 , 0.29361415, 0.28777534,\n",
      "       0.13002857, 0.01936696, 0.67883553, 0.21162812, 0.26554666]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 15, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 1, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='constant', loss='epsilon_insensitive',\n",
      "             max_iter=1000, n_iter_no_change=15, penalty='l1', power_t=0.25,\n",
      "             random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 3000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 1, 'selection': 'random', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=3000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=1, selection='random',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=1000,\n",
      "              normalize=False, tol=0.0001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'auto', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='auto', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 7, 'min_samples_split': 26, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'random'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
      "                      max_features='log2', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=7, min_samples_split=26,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=1, splitter='random')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (38,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_fun': 45000, 'max_iter': 1000, 'momentum': 0.8781174363909454, 'n_iter_no_change': 90, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.8781174363909454, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(38,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_fun=45000, max_iter=1000,\n",
      "             momentum=0.8781174363909454, n_iter_no_change=90,\n",
      "             nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "             solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 9, 'min_samples_split': 42, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=9,\n",
      "                      min_samples_split=42, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=900, n_jobs=-1, oob_score=False,\n",
      "                      random_state=1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 450, 'random_state': 1}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=450, random_state=1)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mae', 'init': None, 'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 44, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 45, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 900, 'n_iter_no_change': 30, 'presort': 'deprecated', 'random_state': 1, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                          learning_rate=0.01, loss='huber', max_depth=44,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=45, min_samples_split=16,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=900,\n",
      "                          n_iter_no_change=30, presort='deprecated',\n",
      "                          random_state=1, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.25, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "X_train: [[0.5        1.         1.         1.         0.2        0.6       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_train: [44.21666665 33.48333329]\n",
      "X_test: [[0.16666667 1.         1.         1.         0.2        0.2       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.33333333 0.         0.04608295]]\n",
      "y_test: [39.22222221 29.75555558] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.25, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed1_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N344, Seed10 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 344\n",
      "len(X_test): 15281\n",
      "len(y_train): 344\n",
      "len(y_test): 15281\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.74100000e+03 4.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 5.00000000e-01 2.70996641e-01 3.59777778e+01]\n",
      " [2.83500000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 0.00000000e+00 5.59910414e-02 3.82222222e+01]]\n",
      "X_test: [[8.96300000e+03 6.00000000e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.50000000e-01 7.29003359e-01 1.77333333e+01]\n",
      " [4.03800000e+03 4.00000000e-01 3.33333333e-01 3.33333333e-01\n",
      "  3.33333333e-01 2.50000000e-01 5.59910414e-02 3.54555556e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=10,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=10,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=10, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=10, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=10), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=10, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(266,), (126, 528), (321, 370, 124)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.83191136, 0.58332174, 0.02517173, 0.70920801, 0.26556613,\n",
      "       0.26360285, 0.15037787, 0.68381843, 0.81660184, 0.33607158,\n",
      "       0.89081653, 0.19812181, 0.03061665, 0.87761494, 0.72743551,\n",
      "       0.54088093, 0.13145815, 0.41366737, 0.77872881, 0.58390137,\n",
      "       0.18263144, 0.82608225, 0.10540183, 0.28357668, 0.06556327,\n",
      "       0.05644419, 0.76545582, 0.01178803, 0.61194334, 0.33188226,\n",
      "       0.55964837, 0.33549965, 0.41118255, 0.0768555 , 0.85304299,\n",
      "       0.43998746, 0.12195415, 0.73173462, 0.13878247, 0.76688005,\n",
      "       0.83198977, 0.30977806, 0.59758229, 0.87239246, 0.98302087,\n",
      "       0.46740328, 0.87574449, 0.2960687 , 0.13129105, 0.84281793]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'l1', 'power_t': 0.25, 'random_state': 10, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='l1', power_t=0.25,\n",
      "             random_state=10, shuffle=False, tol=0.001, validation_fraction=0.1,\n",
      "             verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 10, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=10, selection='cyclic',\n",
      "      tol=0.001, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 9000, 'normalize': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=9000, normalize=True, tol=0.001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'ball_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='ball_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "                    weights='distance')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 10, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=23,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=50, min_samples_split=25,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=10, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 22, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=22, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='sigmoid', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': (321, 370, 124), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 45000, 'max_iter': 3000, 'momentum': 0.06556326635477827, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 10, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(321, 370, 124), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=45000, max_iter=3000,\n",
      "             momentum=0.06556326635477827, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=10,\n",
      "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': True, 'random_state': 10, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=12,\n",
      "                      min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=-1, oob_score=True,\n",
      "                      random_state=10, verbose=0, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 1, 'loss': 'square', 'n_estimators': 450, 'random_state': 10}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=450, random_state=10)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.001, 'loss': 'ls', 'max_depth': 14, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 12, 'min_samples_split': 29, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_iter_no_change': 10, 'presort': 'deprecated', 'random_state': 10, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.001, loss='ls',\n",
      "                          max_depth=14, max_features='log2',\n",
      "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                          min_impurity_split=None, min_samples_leaf=12,\n",
      "                          min_samples_split=29, min_weight_fraction_leaf=0.0,\n",
      "                          n_estimators=300, n_iter_no_change=10,\n",
      "                          presort='deprecated', random_state=10, subsample=1.0,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 0.75, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "X_train: [[0.4        0.33333333 1.         0.33333333 0.5        0.27099664]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.         0.05599104]]\n",
      "y_train: [36.86666662 38.02222218]\n",
      "X_test: [[0.6        1.         1.         1.         0.25       0.72900336]\n",
      " [0.4        0.33333333 0.33333333 0.33333333 0.25       0.05599104]]\n",
      "y_test: [17.79999992 35.68888883] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=0.75, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed10_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N344, Seed42 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 344\n",
      "len(X_test): 15281\n",
      "len(y_train): 344\n",
      "len(y_test): 15281\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.61600000e+03 3.33333333e-01 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 2.00000000e-01 4.00000000e-01 3.96833333e+01]\n",
      " [8.12000000e+03 5.00000000e-01 3.33333333e-01 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 4.23041475e-01 4.35666667e+01]]\n",
      "X_test: [[1.35140000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 4.46082949e-01 3.56999999e+01]\n",
      " [6.70500000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 6.00000000e-01 2.23041475e-01 2.88666666e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=42,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(103,), (436, 861), (271, 107, 72)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.59865848, 0.15601864, 0.15599452, 0.05808361, 0.86617615,\n",
      "       0.60111501, 0.70807258, 0.02058449, 0.96990985, 0.83244264,\n",
      "       0.21233911, 0.18182497, 0.18340451, 0.30424224, 0.52475643,\n",
      "       0.43194502, 0.29122914, 0.61185289, 0.13949386, 0.29214465,\n",
      "       0.36636184, 0.45606998, 0.78517596, 0.19967378, 0.51423444,\n",
      "       0.59241457, 0.04645041, 0.60754485, 0.17052412, 0.06505159,\n",
      "       0.94888554, 0.96563203, 0.80839735, 0.30461377, 0.09767211,\n",
      "       0.68423303, 0.44015249, 0.12203823, 0.49517691, 0.03438852,\n",
      "       0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802,\n",
      "       0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': False, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_epsilon_insensitive', 'max_iter': 9000, 'n_iter_no_change': 45, 'penalty': 'elasticnet', 'power_t': 0.25, 'random_state': 42, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_epsilon_insensitive',\n",
      "             max_iter=9000, n_iter_no_change=45, penalty='elasticnet',\n",
      "             power_t=0.25, random_state=42, shuffle=False, tol=0.001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'random', 'tol': 0.001, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=False, precompute=False, random_state=42, selection='random',\n",
      "      tol=0.001, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 3000, 'normalize': False, 'tol': 1e-05, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=3000, normalize=False, tol=1e-05,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 270, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 16, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=270, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=16, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 26, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=9,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=26, min_samples_split=11,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=42, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 36, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 9000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=36, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='rbf', max_iter=9000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gean/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "best estimator: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (103,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'max_fun': 135000, 'max_iter': 3000, 'momentum': 0.9695846277645586, 'n_iter_no_change': 30, 'nesterovs_momentum': False, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': True}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(103,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.0001, max_fun=135000, max_iter=3000,\n",
      "             momentum=0.9695846277645586, n_iter_no_change=30,\n",
      "             nesterovs_momentum=False, power_t=0.5, random_state=42,\n",
      "             shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "             verbose=False, warm_start=True)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_MLPRegressor.joblib \n",
      "\n",
      "\n",
      "# RandomForestRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mae', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 8, 'min_samples_split': 22, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': True, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
      "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=8,\n",
      "                      min_samples_split=22, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=True,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_RandomForestRegressor.joblib \n",
      "\n",
      "\n",
      "# AdaBoostRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'base_estimator': None, 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 150, 'random_state': 42}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=150, random_state=42)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_AdaBoostRegressor.joblib \n",
      "\n",
      "\n",
      "# GradientBoostingRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'mse', 'init': None, 'learning_rate': 0.001, 'loss': 'lad', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 15, 'min_samples_split': 23, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': 90, 'presort': 'deprecated', 'random_state': 42, 'subsample': 0.5, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mse', init=None,\n",
      "                          learning_rate=0.001, loss='lad', max_depth=5,\n",
      "                          max_features='log2', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=23,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=90, presort='deprecated',\n",
      "                          random_state=42, subsample=0.5, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_GradientBoostingRegressor.joblib \n",
      "\n",
      "\n",
      "# DummyRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'constant': None, 'quantile': 1.0, 'strategy': 'mean'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "X_train: [[0.33333333 1.         1.         1.         0.2        0.4       ]\n",
      " [0.5        0.33333333 1.         1.         0.         0.42304147]]\n",
      "y_train: [40.1666667  43.40000002]\n",
      "X_test: [[0.66666667 0.33333333 1.         0.33333333 0.2        0.44608295]\n",
      " [0.33333333 0.33333333 1.         0.33333333 0.6        0.22304147]]\n",
      "y_test: [37.20000004 29.66666664] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DummyRegressor(constant=None, quantile=1.0, strategy='mean')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed42_DummyRegressor.joblib \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================\n",
      "=========== imagenet16_120, Subset200, N344, Seed100 ===========\n",
      "=========================================================\n",
      "\n",
      "###### set_default_seed() ######\n",
      "\n",
      "###### hold-out process ######\n",
      "len(X_train): 344\n",
      "len(X_test): 15281\n",
      "len(y_train): 344\n",
      "len(y_test): 15281\n",
      "\n",
      "###### Normalization process ######\n",
      "X_train: [[6.84300000e+03 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 3.18082789e-01 3.38166667e+01]\n",
      " [1.31600000e+04 6.66666667e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 3.18082789e-01 4.32666666e+01]]\n",
      "X_test: [[3.28900000e+03 3.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 0.00000000e+00 2.63616558e-01 3.97444443e+01]\n",
      " [4.82500000e+03 8.33333333e-01 3.33333333e-01 1.00000000e+00\n",
      "  3.33333333e-01 2.00000000e-01 5.54466231e-01 4.32499999e+01]]\n",
      "\n",
      "###### get_estimators() ######\n",
      "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False), SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=100,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
      "              compute_score=False, copy_X=True, fit_intercept=True,\n",
      "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform'), DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best'), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=100, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False), RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                      random_state=100, verbose=0, warm_start=False), AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=100), GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=100, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False), DummyRegressor(constant=None, quantile=None, strategy='mean')] \n",
      "\n",
      "###### get_estimators_hyperparameters_to_search() ######\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet'], 'fit_intercept': [False, True], 'max_iter': [1000, 3000, 9000], 'shuffle': [False, True], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'early_stopping': [False, True], 'n_iter_no_change': [5, 15, 45], 'warm_start': [False, True]}\n",
      "{'fit_intercept': [False, True], 'normalize': [False, True], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'positive': [False, True], 'selection': ['cyclic', 'random'], 'tol': [0.001, 0.0001, 1e-05]}\n",
      "{'n_iter': [1000, 3000, 9000], 'tol': [0.001, 0.0001, 1e-05], 'compute_score': [False, True], 'fit_intercept': [False, True], 'normalize': [False, True]}\n",
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [30, 90, 270], 'p': [1, 2]}\n",
      "{'criterion': ['mse', 'friedman_mse', 'mae'], 'splitter': ['best', 'random'], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2']}\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': ['scale', 'auto'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_iter': [1000, 3000, 9000]}\n",
      "{'hidden_layer_sizes': [(521,), (793, 836), (872, 856, 80)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'learning_rate_init': [0.01, 0.001, 0.0001], 'max_iter': [1000, 3000, 9000], 'warm_start': [False, True], 'momentum': array([0.84477613, 0.00471886, 0.12156912, 0.67074908, 0.82585276,\n",
      "       0.13670659, 0.57509333, 0.89132195, 0.20920212, 0.18532822,\n",
      "       0.10837689, 0.21969749, 0.97862378, 0.81168315, 0.17194101,\n",
      "       0.81622475, 0.27407375, 0.43170418, 0.94002982, 0.81764938,\n",
      "       0.33611195, 0.17541045, 0.37283205, 0.00568851, 0.25242635,\n",
      "       0.79566251, 0.01525497, 0.59884338, 0.60380454, 0.10514769,\n",
      "       0.38194344, 0.03647606, 0.89041156, 0.98092086, 0.05994199,\n",
      "       0.89054594, 0.5769015 , 0.74247969, 0.63018394, 0.58184219,\n",
      "       0.02043913, 0.21002658, 0.54468488, 0.76911517, 0.25069523,\n",
      "       0.28589569, 0.85239509, 0.97500649, 0.88485329, 0.35950784]), 'nesterovs_momentum': [False, True], 'early_stopping': [False, True], 'n_iter_no_change': [10, 30, 90], 'max_fun': [15000, 45000, 135000]}\n",
      "{'n_estimators': [100, 300, 900], 'criterion': ['mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'oob_score': [False, True], 'warm_start': [False, True]}\n",
      "{'n_estimators': [50, 150, 450], 'learning_rate': [1, 0.1, 0.01], 'loss': ['linear', 'square', 'exponential']}\n",
      "{'loss': ['ls', 'lad', 'huber', 'quantile'], 'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 300, 900], 'subsample': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], 'max_features': ['auto', 'sqrt', 'log2'], 'warm_start': [False, True], 'n_iter_no_change': [10, 30, 90, None]}\n",
      "{'strategy': ['mean', 'median', 'quantile'], 'quantile': [0.0, 0.25, 0.75, 1.0]} \n",
      "\n",
      "\n",
      "# LinearRegression #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_LinearRegression.joblib \n",
      "\n",
      "\n",
      "# SGDRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 0.0001, 'average': False, 'early_stopping': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_loss', 'max_iter': 1000, 'n_iter_no_change': 45, 'penalty': 'l2', 'power_t': 0.25, 'random_state': 100, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='optimal', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=45, penalty='l2', power_t=0.25, random_state=100,\n",
      "             shuffle=False, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_SGDRegressor.joblib \n",
      "\n",
      "\n",
      "# Lasso #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 9000, 'normalize': True, 'positive': True, 'precompute': False, 'random_state': 100, 'selection': 'cyclic', 'tol': 1e-05, 'warm_start': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=9000, normalize=True,\n",
      "      positive=True, precompute=False, random_state=100, selection='cyclic',\n",
      "      tol=1e-05, warm_start=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_Lasso.joblib \n",
      "\n",
      "\n",
      "# BayesianRidge #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 1000, 'normalize': False, 'tol': 0.0001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None, compute_score=True,\n",
      "              copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,\n",
      "              lambda_init=None, n_iter=1000, normalize=False, tol=0.0001,\n",
      "              verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_BayesianRidge.joblib \n",
      "\n",
      "\n",
      "# KNeighborsRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'algorithm': 'kd_tree', 'leaf_size': 90, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 24, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: KNeighborsRegressor(algorithm='kd_tree', leaf_size=90, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=24, p=1,\n",
      "                    weights='uniform')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_KNeighborsRegressor.joblib \n",
      "\n",
      "\n",
      "# DecisionTreeRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 23, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 100, 'splitter': 'best'}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=27,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=23, min_samples_split=6,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=100, splitter='best')\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_DecisionTreeRegressor.joblib \n",
      "\n",
      "\n",
      "# SVR #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n",
      "DONE\n",
      "best estimator: {'C': 4, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 3000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "######### HOLD-OUT VALIDATION #########\n",
      "Training DONE\n",
      "Testing DONE\n",
      "\n",
      "\n",
      "###### train_and_test_whole() ######\n",
      "estimator: SVR(C=4, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "X_train: [[0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.         0.31808279]]\n",
      "y_train: [33.69999992 43.67777771]\n",
      "X_test: [[0.33333333 0.33333333 1.         0.33333333 0.         0.26361656]\n",
      " [0.83333333 0.33333333 1.         0.33333333 0.2        0.55446623]]\n",
      "y_test: [39.72222218 43.09999999] \n",
      "\n",
      "###### save_estimator() ######\n",
      "estimator: SVR(C=4, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=3000, shrinking=True, tol=0.001, verbose=False)\n",
      "saved file: /home/gean/nns_performance_prediction/saved_models/nasbench201_imagenet16_120_200epochs_n344_seed100_SVR.joblib \n",
      "\n",
      "\n",
      "# MLPRegressor #\n",
      "\n",
      "######### 3 Fold RANDOM SEARCH #########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-52483a075283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features drop:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-b6737aea89d0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n#########\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fold RANDOM SEARCH #########\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0;31m#id_arch and acc_test columns are not included\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1484\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1485\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 691\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"data_path:\", args.data_path)\n",
    "    print(\"model_path:\", args.model_path)\n",
    "    print(\"results_path:\", args.results_path)\n",
    "    print(\"target:\", args.target)\n",
    "    print(\"n_iter_rs:\", args.n_iter_rs)\n",
    "    print(\"cv_inner:\", args.cv_inner)\n",
    "    print(\"scoring_rs:\", args.scoring_rs)\n",
    "    print(\"dataset:\", args.dataset)\n",
    "    print(\"data_subset:\", args.data_subset)\n",
    "    print(\"seed:\", args.seed)\n",
    "    print(\"train_size:\", args.train_size)                \n",
    "    print(\"estimators:\", args.estimators)\n",
    "    print(\"features drop:\", args.features_drop, \"\\n\\n\\n\")\n",
    "    \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
